{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/GNNatan/SemNov_AML_DAAI_23-24.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUikWfJmxLTj",
        "outputId": "c3fae46b-81ca-4150-a80c-3457ba70dd2c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SemNov_AML_DAAI_23-24'...\n",
            "remote: Enumerating objects: 1050, done.\u001b[K\n",
            "remote: Counting objects: 100% (515/515), done.\u001b[K\n",
            "remote: Compressing objects: 100% (302/302), done.\u001b[K\n",
            "remote: Total 1050 (delta 241), reused 404 (delta 202), pack-reused 535\u001b[K\n",
            "Receiving objects: 100% (1050/1050), 3.26 GiB | 22.73 MiB/s, done.\n",
            "Resolving deltas: 100% (313/313), done.\n",
            "Updating files: 100% (734/734), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd SemNov_AML_DAAI_23-24/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4lIZdgmxMrp",
        "outputId": "58c0bd29-384a-45b4-f923-ae23ef29bdc9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SemNov_AML_DAAI_23-24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Rv4bwByPxOEG",
        "outputId": "1da086bc-6b7c-4798-b984-2dcd6d50ac78"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm==0.5.4 (from -r requirements.txt (line 1))\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.5/431.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb (from -r requirements.txt (line 2))\n",
            "  Downloading wandb-0.17.1-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.66.4)\n",
            "Collecting h5py==3.6.0 (from -r requirements.txt (line 4))\n",
            "  Downloading h5py-3.6.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==3.20.1 (from -r requirements.txt (line 5))\n",
            "  Downloading protobuf-3.20.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lmdb==1.2.1 (from -r requirements.txt (line 6))\n",
            "  Downloading lmdb-1.2.1.tar.gz (881 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.5/881.5 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting msgpack-numpy==0.4.7.1 (from -r requirements.txt (line 7))\n",
            "  Downloading msgpack_numpy-0.4.7.1-py2.py3-none-any.whl (6.7 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from timm==0.5.4->-r requirements.txt (line 1)) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.5.4->-r requirements.txt (line 1)) (0.18.0+cu121)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.10/dist-packages (from h5py==3.6.0->-r requirements.txt (line 4)) (1.25.2)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from msgpack-numpy==0.4.7.1->-r requirements.txt (line 7)) (1.0.8)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 2)) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 2))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 2))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 2)) (4.2.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 2)) (2.31.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 2))\n",
            "  Downloading sentry_sdk-2.5.1-py2.py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.6/289.6 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb->-r requirements.txt (line 2))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 2)) (67.7.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 8)) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 8)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 8)) (3.5.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 2)) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 2))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 2)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 2)) (2024.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1)) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1)) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1)) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1)) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.5.4->-r requirements.txt (line 1)) (9.4.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 2))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4->timm==0.5.4->-r requirements.txt (line 1)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->timm==0.5.4->-r requirements.txt (line 1)) (1.3.0)\n",
            "Building wheels for collected packages: lmdb\n",
            "  Building wheel for lmdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lmdb: filename=lmdb-1.2.1-cp310-cp310-linux_x86_64.whl size=265655 sha256=f25d59f2e8d506ecb4022deb2825accca8cbebc9f459422da1c39013b9ad0ee1\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/36/fc/13e586283759d30c3efc3d0b917b2c5f1b69d171de8b7ed204\n",
            "Successfully built lmdb\n",
            "Installing collected packages: lmdb, smmap, setproctitle, sentry-sdk, protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgpack-numpy, h5py, docker-pycreds, nvidia-cusparse-cu12, nvidia-cudnn-cu12, gitdb, nvidia-cusolver-cu12, gitpython, wandb, timm\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-ai-generativelanguage 0.6.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-aiplatform 1.52.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.25.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-datastore 2.15.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-firestore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-functions 1.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-iam 2.15.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-language 2.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-resource-manager 1.12.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-translate 3.11.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "googleapis-common-protos 1.63.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.1 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 3.20.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 h5py-3.6.0 lmdb-1.2.1 msgpack-numpy-0.4.7.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 protobuf-3.20.1 sentry-sdk-2.5.1 setproctitle-1.3.3 smmap-5.0.1 timm-0.5.4 wandb-0.17.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "d83afb09576548ddb4d537c2dd7bbaee"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sh download_data.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMsS84SpxPkY",
        "outputId": "e6f1356d-811a-4ea5-f53c-09602a727a4f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data in /content/SemNov_AML_DAAI_23-24/3D_OS_release_data\n",
            "============Downloading ModelNet40 + OOD Splits in \n",
            "--2024-06-11 16:34:06--  https://www.dropbox.com/s/c2x3h59nxprjs21/modelnet40_normal_resampled.tar?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/dl/c2x3h59nxprjs21/modelnet40_normal_resampled.tar [following]\n",
            "--2024-06-11 16:34:07--  https://www.dropbox.com/s/dl/c2x3h59nxprjs21/modelnet40_normal_resampled.tar\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc5601b6b581f18ca5fe6cf96dec.dl.dropboxusercontent.com/cd/0/get/CUpp2bo3sf0BpRwh1c5uWw12p9gEwm2lAxre6dXl7q7tMpeyEoafM-jD8LdS_a8wkcBTucGC_IoZCsS-YGeq8vL0vvk88Fxb65U1jVG0kZlUN0UKdySIw1SgDkwqbNJjPnLDf93qy0rFmFuh6PzKe1Ow/file?dl=1# [following]\n",
            "--2024-06-11 16:34:08--  https://uc5601b6b581f18ca5fe6cf96dec.dl.dropboxusercontent.com/cd/0/get/CUpp2bo3sf0BpRwh1c5uWw12p9gEwm2lAxre6dXl7q7tMpeyEoafM-jD8LdS_a8wkcBTucGC_IoZCsS-YGeq8vL0vvk88Fxb65U1jVG0kZlUN0UKdySIw1SgDkwqbNJjPnLDf93qy0rFmFuh6PzKe1Ow/file?dl=1\n",
            "Resolving uc5601b6b581f18ca5fe6cf96dec.dl.dropboxusercontent.com (uc5601b6b581f18ca5fe6cf96dec.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601f:15::a27d:90f\n",
            "Connecting to uc5601b6b581f18ca5fe6cf96dec.dl.dropboxusercontent.com (uc5601b6b581f18ca5fe6cf96dec.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7599001600 (7.1G) [application/binary]\n",
            "Saving to: ‘/content/SemNov_AML_DAAI_23-24/3D_OS_release_data/tmp_modelnet40_normal_resampled.tar’\n",
            "\n",
            "/content/SemNov_AML 100%[===================>]   7.08G  71.2MB/s    in 1m 46s  \n",
            "\n",
            "2024-06-11 16:35:54 (68.4 MB/s) - ‘/content/SemNov_AML_DAAI_23-24/3D_OS_release_data/tmp_modelnet40_normal_resampled.tar’ saved [7599001600/7599001600]\n",
            "\n",
            "============\n",
            "============Downloading ScanObjectNN in \n",
            "--2024-06-11 16:37:16--  https://www.dropbox.com/s/gu0p3rych1k26b7/ScanObjectNN.tar?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601b:18::a27d:812\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/dl/gu0p3rych1k26b7/ScanObjectNN.tar [following]\n",
            "--2024-06-11 16:37:16--  https://www.dropbox.com/s/dl/gu0p3rych1k26b7/ScanObjectNN.tar\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uce74a45fd9ed0764b4235976c80.dl.dropboxusercontent.com/cd/0/get/CUob0AoWx5CbKUwglMSrfPMwv6GChxlHJXAxtW41YhrosKU0qBNRebxQmgKgeB57NG2wwkMHqEcVe12xHweCVDsCMMLCQH4jEyXOv0wA1XNPn4RyJj61EsiT2CQsSiWnLEXTYy2qTCkCWEB9rjonTk3p/file?dl=1# [following]\n",
            "--2024-06-11 16:37:17--  https://uce74a45fd9ed0764b4235976c80.dl.dropboxusercontent.com/cd/0/get/CUob0AoWx5CbKUwglMSrfPMwv6GChxlHJXAxtW41YhrosKU0qBNRebxQmgKgeB57NG2wwkMHqEcVe12xHweCVDsCMMLCQH4jEyXOv0wA1XNPn4RyJj61EsiT2CQsSiWnLEXTYy2qTCkCWEB9rjonTk3p/file?dl=1\n",
            "Resolving uce74a45fd9ed0764b4235976c80.dl.dropboxusercontent.com (uce74a45fd9ed0764b4235976c80.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uce74a45fd9ed0764b4235976c80.dl.dropboxusercontent.com (uce74a45fd9ed0764b4235976c80.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2623662080 (2.4G) [application/binary]\n",
            "Saving to: ‘/content/SemNov_AML_DAAI_23-24/3D_OS_release_data/tmp_ScanObjectNN.tar’\n",
            "\n",
            "/content/SemNov_AML 100%[===================>]   2.44G  64.2MB/s    in 63s     \n",
            "\n",
            "2024-06-11 16:38:21 (39.6 MB/s) - ‘/content/SemNov_AML_DAAI_23-24/3D_OS_release_data/tmp_ScanObjectNN.tar’ saved [2623662080/2623662080]\n",
            "\n",
            "============\n",
            "Finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import h5py\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import sample\n",
        "from mpl_toolkits.mplot3d import proj3d\n",
        "from notebooks.utils import *\n",
        "from utils import ood_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beu-aLBN0gdc",
        "outputId": "dbd7f6c5-b255-4d3b-df39-ab21bfdf842f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot import torchlars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SR1 = {\n",
        "    4: 0,  # chair\n",
        "    8: 1,  # shelf\n",
        "    7: 2,  # door\n",
        "    12: 3,  # sink\n",
        "    13: 4  # sofa\n",
        "}\n",
        "\n",
        "SR2 = {\n",
        "    10: 0,  # bed\n",
        "    14: 1,  # toilet\n",
        "    5: 2,  # desk\n",
        "    6: 3,  # display\n",
        "    9: 2  # table\n",
        "}\n",
        "\n",
        "SR3 = {\n",
        "    0: 404,  # bag\n",
        "    1: 404,  # bin\n",
        "    2: 404,  # box\n",
        "    3: 404,  # cabinet\n",
        "    11: 404  # pillow\n",
        "}\n",
        "\n",
        "test_file = h5py.File('3D_OS_release_data/ScanObjectNN/h5_files/main_split/test_objectdataset.h5', 'r')\n",
        "train_file = h5py.File('3D_OS_release_data/ScanObjectNN/h5_files/main_split/training_objectdataset.h5', 'r')\n",
        "\n",
        "test_labels  = test_file['label'][:]\n",
        "train_labels = train_file['label'][:]\n",
        "\n",
        "test_clouds = test_file['data'][:]\n",
        "train_clouds = train_file['data'][:]\n",
        "\n",
        "all_labels = np.hstack((train_labels, test_labels))\n",
        "all_clouds = np.vstack((train_clouds, test_clouds))\n",
        "\n",
        "SR1_indices = [index for index, value in enumerate(all_labels) if value in SR1.keys()]\n",
        "SR2_indices = [index for index, value in enumerate(all_labels) if value in SR2.keys()]\n",
        "SR3_indices = [index for index, value in enumerate(all_labels) if value in SR3.keys()]\n",
        "\n",
        "SR1_clouds = all_clouds[SR1_indices]\n",
        "SR2_clouds = all_clouds[SR2_indices]\n",
        "SR3_clouds = all_clouds[SR3_indices]\n",
        "\n",
        "SR1_labels = [SR1[all_labels[id]] for id in SR1_indices]\n",
        "SR2_labels = [SR2[all_labels[id]] for id in SR2_indices]\n",
        "SR3_labels = [404 for _ in SR3_indices]"
      ],
      "metadata": {
        "id": "n3dx33Nyxj45"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PqYrEy4xxA9x"
      },
      "outputs": [],
      "source": [
        "## OPENSHAPE - MAXIMUM SOFTMAX PROBABILITY\n",
        "sr1_img_scores = load_from_file('/content/SemNov_AML_DAAI_23-24/outputs/tensors/OpenShape_SR1/img_scores.pt')\n",
        "sr2_img_scores = load_from_file('/content/SemNov_AML_DAAI_23-24/outputs/tensors/OpenShape_SR2/img_scores.pt')\n",
        "sr1_txt_scores = load_from_file('/content/SemNov_AML_DAAI_23-24/outputs/tensors/OpenShape_SR1/text_scores.pt')\n",
        "sr2_txt_scores = load_from_file('/content/SemNov_AML_DAAI_23-24/outputs/tensors/OpenShape_SR2/text_scores.pt')\n",
        "\n",
        "\n",
        "openshape_sr1_scores = sr1_img_scores + sr1_txt_scores\n",
        "openshape_sr2_scores = sr2_img_scores + sr2_txt_scores\n",
        "\n",
        "sr1_src_logits = torch.tensor(np.array([openshape_sr1_scores[i] for i in SR1_indices])).squeeze(1)\n",
        "sr1_tar1_logits = torch.tensor(np.array([openshape_sr1_scores[i] for i in SR2_indices])).squeeze(1)\n",
        "sr1_tar2_logits = torch.tensor(np.array([openshape_sr1_scores[i] for i in SR3_indices])).squeeze(1)\n",
        "\n",
        "sr1_src_MSP_scores, sr1_src_MSP_pred = sr1_src_logits.max(1)\n",
        "sr1_tar1_MSP_scores, sr1_tar1_MSP_pred = sr1_tar1_logits.max(1)\n",
        "sr1_tar2_MSP_scores, sr1_tar2_MSP_pred = sr1_tar2_logits.max(1)\n",
        "\n",
        "\n",
        "sr2_src_logits = torch.tensor(np.array([openshape_sr2_scores[i] for i in SR2_indices])).squeeze(1)\n",
        "sr2_tar1_logits = torch.tensor(np.array([openshape_sr2_scores[i] for i in SR1_indices])).squeeze(1)\n",
        "sr2_tar2_logits = torch.tensor(np.array([openshape_sr2_scores[i] for i in SR3_indices])).squeeze(1)\n",
        "\n",
        "# merge desk and table prediction into same class for SR2\n",
        "sr2_src_table = sr2_src_logits[:, 2] + sr2_src_logits[:, 4]\n",
        "sr2_tar1_table = sr2_tar1_logits[:, 2] + sr2_tar1_logits[:, 4]\n",
        "sr2_tar2_table = sr2_tar2_logits[:, 2] + sr2_tar2_logits[:, 4]\n",
        "\n",
        "sr2_src_logits = torch.cat((sr2_src_logits[:, :2], sr2_src_table.unsqueeze(1), sr2_src_logits[:, 3].unsqueeze(1)), dim=1)\n",
        "sr2_tar1_logits = torch.cat((sr2_tar1_logits[:, :2], sr2_tar1_table.unsqueeze(1), sr2_tar1_logits[:, 3].unsqueeze(1)), dim=1)\n",
        "sr2_tar2_logits = torch.cat((sr2_tar2_logits[:, :2], sr2_tar2_table.unsqueeze(1), sr2_tar2_logits[:, 3].unsqueeze(1)), dim=1)\n",
        "\n",
        "\n",
        "sr2_src_MSP_scores, sr2_src_MSP_pred = sr2_src_logits.max(1)\n",
        "sr2_tar1_MSP_scores, sr2_tar1_MSP_pred = sr2_tar1_logits.max(1)\n",
        "sr2_tar2_MSP_scores, sr2_tar2_MSP_pred = sr2_tar2_logits.max(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ood_utils.eval_ood_sncore(\n",
        "    scores_list = [sr1_src_MSP_scores, sr1_tar1_MSP_scores, sr1_tar2_MSP_scores],\n",
        "    preds_list = [sr1_src_MSP_pred, None, None],\n",
        "    labels_list = [SR1_labels, None, None],\n",
        "    src_label = 1\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ2f21pYxE5t",
        "outputId": "116556a0-6ebb-4ba2-918b-51325e18f289"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC - Src label: 1, Tar label: 0\n",
            "Src Test - Clf Acc: 0.8589641434262948, Clf Bal Acc: 0.8378403945607398\n",
            "SRC->TAR1:      AUROC: 0.8682, FPR95: 0.7449, AUPR_IN: 0.9241, AUPR_OUT: 0.7439\n",
            "SRC->TAR2:      AUROC: 0.8458, FPR95: 0.6021, AUPR_IN: 0.8848, AUPR_OUT: 0.7880\n",
            "SRC->TAR1+TAR2: AUROC: 0.8566, FPR95: 0.6709, AUPR_IN: 0.8363, AUPR_OUT: 0.8661\n",
            "to spreadsheet: 0.8682452929399154,0.7449238578680203,0.9240610777104156,0.7438754143772683,0.8458200256823943,0.602125147579693,0.8847589164368889,0.7879571993315008,0.8566280443973342,0.6709480122324158,0.8362922890684257,0.8660990804528985\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8589641434262948,\n",
              " 0.8378403945607398,\n",
              " {'fpr_at_95_tpr': 0.7449238578680203,\n",
              "  'detection_error': 0.4766561553057779,\n",
              "  'auroc': 0.8682452929399154,\n",
              "  'aupr_in': 0.9240610777104156,\n",
              "  'aupr_out': 0.7438754143772683},\n",
              " {'fpr_at_95_tpr': 0.602125147579693,\n",
              "  'detection_error': 0.3794057492453425,\n",
              "  'auroc': 0.8458200256823943,\n",
              "  'aupr_in': 0.8847589164368889,\n",
              "  'aupr_out': 0.7879571993315008},\n",
              " {'fpr_at_95_tpr': 0.6709480122324158,\n",
              "  'detection_error': 0.31931234038692585,\n",
              "  'auroc': 0.8566280443973342,\n",
              "  'aupr_in': 0.8362922890684257,\n",
              "  'aupr_out': 0.8660990804528985})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ood_utils.eval_ood_sncore(\n",
        "    scores_list = [sr2_src_MSP_scores, sr2_tar1_MSP_scores, sr2_tar2_MSP_scores],\n",
        "    preds_list = [sr2_src_MSP_pred, None, None],\n",
        "    labels_list = [SR2_labels, None, None],\n",
        "    src_label = 1\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcWOuzU3xaEG",
        "outputId": "500bf4ff-74ef-40a5-c38b-c9f1234d278e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC - Src label: 1, Tar label: 0\n",
            "Src Test - Clf Acc: 0.5203045685279187, Clf Bal Acc: 0.30559854397948993\n",
            "SRC->TAR1:      AUROC: 0.5875, FPR95: 0.9641, AUPR_IN: 0.4817, AUPR_OUT: 0.6510\n",
            "SRC->TAR2:      AUROC: 0.5577, FPR95: 0.9374, AUPR_IN: 0.5191, AUPR_OUT: 0.5642\n",
            "SRC->TAR1+TAR2: AUROC: 0.5755, FPR95: 0.9534, AUPR_IN: 0.3321, AUPR_OUT: 0.7594\n",
            "to spreadsheet: 0.587483568265011,0.9641434262948207,0.4816855573357774,0.6510431857346664,0.5576684506079983,0.9374262101534829,0.519082694128402,0.5641997510658865,0.5754695793708674,0.9533777354900095,0.3320659469930958,0.7593592786485661\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5203045685279187,\n",
              " 0.30559854397948993,\n",
              " {'fpr_at_95_tpr': 0.9641434262948207,\n",
              "  'detection_error': 0.38509262021907475,\n",
              "  'auroc': 0.587483568265011,\n",
              "  'aupr_in': 0.4816855573357774,\n",
              "  'aupr_out': 0.6510431857346664},\n",
              " {'fpr_at_95_tpr': 0.9374262101534829,\n",
              "  'detection_error': 0.47589707899102784,\n",
              "  'auroc': 0.5576684506079983,\n",
              "  'aupr_in': 0.519082694128402,\n",
              "  'aupr_out': 0.5641997510658865},\n",
              " {'fpr_at_95_tpr': 0.9533777354900095,\n",
              "  'detection_error': 0.2717563434395978,\n",
              "  'auroc': 0.5754695793708674,\n",
              "  'aupr_in': 0.3320659469930958,\n",
              "  'aupr_out': 0.7593592786485661})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OPENSHAPE - DISTANCE BASED EVALUATION\n",
        "\n",
        "sr1_train_labels = load_from_file('/content/SemNov_AML_DAAI_23-24/outputs/tensors/OpenShape_SR1/train_labels.pt')\n",
        "sr1_src_labels = load_from_file('/content/SemNov_AML_DAAI_23-24/outputs/tensors/OpenShape_SR1/src_labels.pt')\n",
        "sr1_src_dist = load_from_file('/content/SemNov_AML_DAAI_23-24/outputs/tensors/OpenShape_SR1/src_dist.pt')\n",
        "sr1_src_ids = load_from_file('/content/SemNov_AML_DAAI_23-24/outputs/tensors/OpenShape_SR1/src_ids.pt')\n",
        "sr1_tar1_dist = load_from_file('/content/SemNov_AML_DAAI_23-24/outputs/tensors/OpenShape_SR1/tar1_dist.pt')\n",
        "sr1_tar1_ids = load_from_file('/content/SemNov_AML_DAAI_23-24/outputs/tensors/OpenShape_SR1/tar1_ids.pt')\n",
        "sr1_tar2_dist = load_from_file('/content/SemNov_AML_DAAI_23-24/outputs/tensors/OpenShape_SR1/tar2_dist.pt')\n",
        "sr1_tar2_ids = load_from_file('/content/SemNov_AML_DAAI_23-24/outputs/tensors/OpenShape_SR1/tar2_dist.pt')\n",
        "\n",
        "\n",
        "sr2_train_labels = load_from_file('/content/SemNov_AML_DAAI_23-24/outputs/tensors/OpenShape_SR2/train_labels.pt')\n",
        "sr2_src_labels = load_from_file('/content/SemNov_AML_DAAI_23-24/outputs/tensors/OpenShape_SR2/src_labels.pt')\n",
        "sr2_src_dist = load_from_file('/content/SemNov_AML_DAAI_23-24/outputs/tensors/OpenShape_SR2/src_dist.pt')\n",
        "sr2_src_ids = load_from_file('/content/SemNov_AML_DAAI_23-24/outputs/tensors/OpenShape_SR2/src_ids.pt')\n",
        "sr2_tar1_dist = load_from_file('/content/SemNov_AML_DAAI_23-24/outputs/tensors/OpenShape_SR2/tar1_dist.pt')\n",
        "sr2_tar1_ids = load_from_file('/content/SemNov_AML_DAAI_23-24/outputs/tensors/OpenShape_SR2/tar1_ids.pt')\n",
        "sr2_tar2_dist = load_from_file('/content/SemNov_AML_DAAI_23-24/outputs/tensors/OpenShape_SR2/tar2_dist.pt')\n",
        "sr2_tar2_ids = load_from_file('/content/SemNov_AML_DAAI_23-24/outputs/tensors/OpenShape_SR2/tar2_dist.pt')"
      ],
      "metadata": {
        "id": "WTOP5sNn1KJl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sr1_src_scores = 1 / sr1_src_dist\n",
        "sr1_src_pred = np.asarray([sr1_train_labels[i] for i in sr1_src_ids])  # pred is label of nearest training sample\n",
        "sr1_tar1_scores = 1 / sr1_tar1_dist\n",
        "sr1_tar2_scores = 1 / sr1_tar2_dist"
      ],
      "metadata": {
        "id": "PLRad55uLj60"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ood_utils.eval_ood_sncore(\n",
        "        scores_list=[sr1_src_scores, sr1_tar1_scores, sr1_tar2_scores],\n",
        "        preds_list=[sr1_src_pred, None, None],\n",
        "        labels_list=[sr1_src_labels, None, None],\n",
        "        src_label=1  # confidence should be higher for ID samples\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TuGxnBkL2v_",
        "outputId": "8d0c4411-6149-4a01-9929-8badc99c1eda"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC - Src label: 1, Tar label: 0\n",
            "Src Test - Clf Acc: 0.9139442231075697, Clf Bal Acc: 0.917365080048558\n",
            "SRC->TAR1:      AUROC: 0.7842, FPR95: 0.8185, AUPR_IN: 0.8686, AUPR_OUT: 0.6414\n",
            "SRC->TAR2:      AUROC: 0.8087, FPR95: 0.8135, AUPR_IN: 0.8794, AUPR_OUT: 0.6769\n",
            "SRC->TAR1+TAR2: AUROC: 0.7969, FPR95: 0.8159, AUPR_IN: 0.7947, AUPR_OUT: 0.7930\n",
            "to spreadsheet: 0.7841517180010921,0.8185279187817259,0.8685865952839535,0.6414371478091789,0.8087348363335325,0.8134592680047226,0.8793713072348379,0.6769219669952151,0.7968868257855428,0.8159021406727829,0.7947343079708069,0.7930141626375626\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9139442231075697,\n",
              " 0.917365080048558,\n",
              " {'fpr_at_95_tpr': 0.8185279187817259,\n",
              "  'detection_error': 0.5212559201389987,\n",
              "  'auroc': 0.7841517180010921,\n",
              "  'aupr_in': 0.8685865952839535,\n",
              "  'aupr_out': 0.6414371478091789},\n",
              " {'fpr_at_95_tpr': 0.8134592680047226,\n",
              "  'detection_error': 0.5049407256186057,\n",
              "  'auroc': 0.8087348363335325,\n",
              "  'aupr_in': 0.8793713072348379,\n",
              "  'aupr_out': 0.6769219669952151},\n",
              " {'fpr_at_95_tpr': 0.8159021406727829,\n",
              "  'detection_error': 0.3813579644365513,\n",
              "  'auroc': 0.7968868257855428,\n",
              "  'aupr_in': 0.7947343079708069,\n",
              "  'aupr_out': 0.7930141626375626})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sr2_src_scores = 1 / sr2_src_dist\n",
        "sr2_src_pred = np.asarray([sr2_train_labels[i] for i in sr2_src_ids])  # pred is label of nearest training sample\n",
        "sr2_tar1_scores = 1 / sr2_tar1_dist\n",
        "sr2_tar2_scores = 1 / sr2_tar2_dist"
      ],
      "metadata": {
        "id": "3F5UgBJfMUk3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ood_utils.eval_ood_sncore(\n",
        "        scores_list=[sr2_src_scores, sr2_tar1_scores, sr2_tar2_scores],\n",
        "        preds_list=[sr2_src_pred, None, None],\n",
        "        labels_list=[sr2_src_labels, None, None],\n",
        "        src_label=1  # confidence should be higher for ID samples\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcrSzIaMMWAc",
        "outputId": "f5b67478-d611-41b9-82a4-75e76f46b3f9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC - Src label: 1, Tar label: 0\n",
            "Src Test - Clf Acc: 0.5647208121827412, Clf Bal Acc: 0.730759124314575\n",
            "SRC->TAR1:      AUROC: 0.6684, FPR95: 0.8255, AUPR_IN: 0.5621, AUPR_OUT: 0.7620\n",
            "SRC->TAR2:      AUROC: 0.5275, FPR95: 0.9634, AUPR_IN: 0.5588, AUPR_OUT: 0.5185\n",
            "SRC->TAR1+TAR2: AUROC: 0.6117, FPR95: 0.8811, AUPR_IN: 0.4003, AUPR_OUT: 0.8029\n",
            "to spreadsheet: 0.6684439905353207,0.8254980079681274,0.5621351264676989,0.7620142858987206,0.5275037606601981,0.9634002361275088,0.5588437021340469,0.5185239463689529,0.6116521852526239,0.8810656517602283,0.40033548514621436,0.8028990916596447\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5647208121827412,\n",
              " 0.730759124314575,\n",
              " {'fpr_at_95_tpr': 0.8254980079681274,\n",
              "  'detection_error': 0.3488034138234562,\n",
              "  'auroc': 0.6684439905353207,\n",
              "  'aupr_in': 0.5621351264676989,\n",
              "  'aupr_out': 0.7620142858987206},\n",
              " {'fpr_at_95_tpr': 0.9634002361275088,\n",
              "  'detection_error': 0.47955409274211325,\n",
              "  'auroc': 0.5275037606601981,\n",
              "  'aupr_in': 0.5588437021340469,\n",
              "  'aupr_out': 0.5185239463689529},\n",
              " {'fpr_at_95_tpr': 0.8810656517602283,\n",
              "  'detection_error': 0.26171343791472856,\n",
              "  'auroc': 0.6116521852526239,\n",
              "  'aupr_in': 0.40033548514621436,\n",
              "  'aupr_out': 0.8028990916596447})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}