{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "aIgX_jCMZKZt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6lwyLEjw7g2",
        "outputId": "770fb537-9a5a-4930-abd2-08ded8a56c47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SemNov_AML_DAAI_23-24'...\n",
            "remote: Enumerating objects: 1082, done.\u001b[K\n",
            "remote: Counting objects: 100% (547/547), done.\u001b[K\n",
            "remote: Compressing objects: 100% (324/324), done.\u001b[K\n",
            "remote: Total 1082 (delta 260), reused 426 (delta 212), pack-reused 535\u001b[K\n",
            "Receiving objects: 100% (1082/1082), 3.26 GiB | 26.33 MiB/s, done.\n",
            "Resolving deltas: 100% (332/332), done.\n",
            "Updating files: 100% (739/739), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/GNNatan/SemNov_AML_DAAI_23-24.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W24z-eQjxLgn",
        "outputId": "37b9bf8d-b819-4fd7-bc24-b38149d89b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SemNov_AML_DAAI_23-24\n"
          ]
        }
      ],
      "source": [
        "%cd SemNov_AML_DAAI_23-24/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n8ABxdigxzj1",
        "outputId": "604ee0bd-a495-45b3-dd6d-b1bd361d020f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm==0.5.4 (from -r requirements.txt (line 1))\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.5/431.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb (from -r requirements.txt (line 2))\n",
            "  Downloading wandb-0.17.1-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.66.4)\n",
            "Collecting h5py==3.6.0 (from -r requirements.txt (line 4))\n",
            "  Downloading h5py-3.6.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==3.20.1 (from -r requirements.txt (line 5))\n",
            "  Downloading protobuf-3.20.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lmdb==1.2.1 (from -r requirements.txt (line 6))\n",
            "  Downloading lmdb-1.2.1.tar.gz (881 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.5/881.5 kB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting msgpack-numpy==0.4.7.1 (from -r requirements.txt (line 7))\n",
            "  Downloading msgpack_numpy-0.4.7.1-py2.py3-none-any.whl (6.7 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from timm==0.5.4->-r requirements.txt (line 1)) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.5.4->-r requirements.txt (line 1)) (0.18.0+cu121)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.10/dist-packages (from h5py==3.6.0->-r requirements.txt (line 4)) (1.25.2)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from msgpack-numpy==0.4.7.1->-r requirements.txt (line 7)) (1.0.8)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 2)) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 2))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 2))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 2)) (4.2.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 2)) (2.31.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 2))\n",
            "  Downloading sentry_sdk-2.5.1-py2.py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.6/289.6 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb->-r requirements.txt (line 2))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 2)) (67.7.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 8)) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 8)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 8)) (3.5.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 2)) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 2))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 2)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 2)) (2024.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1)) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1)) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4->-r requirements.txt (line 1)) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4->timm==0.5.4->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.5.4->-r requirements.txt (line 1)) (9.4.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 2))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4->timm==0.5.4->-r requirements.txt (line 1)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->timm==0.5.4->-r requirements.txt (line 1)) (1.3.0)\n",
            "Building wheels for collected packages: lmdb\n",
            "  Building wheel for lmdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lmdb: filename=lmdb-1.2.1-cp310-cp310-linux_x86_64.whl size=265649 sha256=11501ff7dde8f45fe3d14f2c3b6fe3bf122f1247a440897e6e66f9c9b45931d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/36/fc/13e586283759d30c3efc3d0b917b2c5f1b69d171de8b7ed204\n",
            "Successfully built lmdb\n",
            "Installing collected packages: lmdb, smmap, setproctitle, sentry-sdk, protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgpack-numpy, h5py, docker-pycreds, nvidia-cusparse-cu12, nvidia-cudnn-cu12, gitdb, nvidia-cusolver-cu12, gitpython, wandb, timm\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-ai-generativelanguage 0.6.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-aiplatform 1.54.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.25.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-datastore 2.15.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-firestore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-functions 1.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-iam 2.15.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-language 2.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-resource-manager 1.12.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-translate 3.11.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "googleapis-common-protos 1.63.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.1 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 3.20.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 h5py-3.6.0 lmdb-1.2.1 msgpack-numpy-0.4.7.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 protobuf-3.20.1 sentry-sdk-2.5.1 setproctitle-1.3.3 smmap-5.0.1 timm-0.5.4 wandb-0.17.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "66bb0083295741049362ffec5660fe36"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CDe1e70uBDIy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cddbcf5-d96d-4413-9596-11cef77f0661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data in /content/SemNov_AML_DAAI_23-24/3D_OS_release_data\n",
            "============Downloading ModelNet40 + OOD Splits in \n",
            "--2024-06-13 15:29:35--  https://www.dropbox.com/s/c2x3h59nxprjs21/modelnet40_normal_resampled.tar?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:6057:18::a27d:d12\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/dl/c2x3h59nxprjs21/modelnet40_normal_resampled.tar [following]\n",
            "--2024-06-13 15:29:36--  https://www.dropbox.com/s/dl/c2x3h59nxprjs21/modelnet40_normal_resampled.tar\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc47c810cb1be38cb9ed3c3dbb31.dl.dropboxusercontent.com/cd/0/get/CUzOKrdMC7W4tO-vBfnuEzk6zsod9Viak8vp-nTg02zjlGiLF9bcdVt-WTiwWec_8iGwwt9cJoYalq5Wdv-vcS4fEK_GsJ6NcTDmxaf9l9WDJRtg2WVx3_1hfx4AZTwUw8RCKeHrHJrSMdewpdHSF1wW/file?dl=1# [following]\n",
            "--2024-06-13 15:29:36--  https://uc47c810cb1be38cb9ed3c3dbb31.dl.dropboxusercontent.com/cd/0/get/CUzOKrdMC7W4tO-vBfnuEzk6zsod9Viak8vp-nTg02zjlGiLF9bcdVt-WTiwWec_8iGwwt9cJoYalq5Wdv-vcS4fEK_GsJ6NcTDmxaf9l9WDJRtg2WVx3_1hfx4AZTwUw8RCKeHrHJrSMdewpdHSF1wW/file?dl=1\n",
            "Resolving uc47c810cb1be38cb9ed3c3dbb31.dl.dropboxusercontent.com (uc47c810cb1be38cb9ed3c3dbb31.dl.dropboxusercontent.com)... 162.125.13.15, 2620:100:6057:15::a27d:d0f\n",
            "Connecting to uc47c810cb1be38cb9ed3c3dbb31.dl.dropboxusercontent.com (uc47c810cb1be38cb9ed3c3dbb31.dl.dropboxusercontent.com)|162.125.13.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7599001600 (7.1G) [application/binary]\n",
            "Saving to: ‘/content/SemNov_AML_DAAI_23-24/3D_OS_release_data/tmp_modelnet40_normal_resampled.tar’\n",
            "\n",
            "/content/SemNov_AML 100%[===================>]   7.08G   118MB/s    in 79s     \n",
            "\n",
            "2024-06-13 15:30:55 (91.9 MB/s) - ‘/content/SemNov_AML_DAAI_23-24/3D_OS_release_data/tmp_modelnet40_normal_resampled.tar’ saved [7599001600/7599001600]\n",
            "\n",
            "============\n",
            "============Downloading ScanObjectNN in \n",
            "--2024-06-13 15:31:33--  https://www.dropbox.com/s/gu0p3rych1k26b7/ScanObjectNN.tar?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.66.18, 2620:100:6022:18::a27d:4212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.66.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/dl/gu0p3rych1k26b7/ScanObjectNN.tar [following]\n",
            "--2024-06-13 15:31:34--  https://www.dropbox.com/s/dl/gu0p3rych1k26b7/ScanObjectNN.tar\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc64f9115538d52ccbe27654c77d.dl.dropboxusercontent.com/cd/0/get/CUxBcnPPK0zo1fxUGMzGZ3aUCcRKwg_FKG88Tu9pAAGV9B0-0DBBVkXMIgdBR7lz1al_6ehvti1FQ4k4OBoucDl23kBLJOnBA3WTZ5GHHbNz1uVusgKl2q6VBskPEt_npFyBVHVxQ9lnyZ2TImkOgsK9/file?dl=1# [following]\n",
            "--2024-06-13 15:31:34--  https://uc64f9115538d52ccbe27654c77d.dl.dropboxusercontent.com/cd/0/get/CUxBcnPPK0zo1fxUGMzGZ3aUCcRKwg_FKG88Tu9pAAGV9B0-0DBBVkXMIgdBR7lz1al_6ehvti1FQ4k4OBoucDl23kBLJOnBA3WTZ5GHHbNz1uVusgKl2q6VBskPEt_npFyBVHVxQ9lnyZ2TImkOgsK9/file?dl=1\n",
            "Resolving uc64f9115538d52ccbe27654c77d.dl.dropboxusercontent.com (uc64f9115538d52ccbe27654c77d.dl.dropboxusercontent.com)... 162.125.13.15, 2620:100:6022:15::a27d:420f\n",
            "Connecting to uc64f9115538d52ccbe27654c77d.dl.dropboxusercontent.com (uc64f9115538d52ccbe27654c77d.dl.dropboxusercontent.com)|162.125.13.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2623662080 (2.4G) [application/binary]\n",
            "Saving to: ‘/content/SemNov_AML_DAAI_23-24/3D_OS_release_data/tmp_ScanObjectNN.tar’\n",
            "\n",
            "/content/SemNov_AML 100%[===================>]   2.44G   106MB/s    in 25s     \n",
            "\n",
            "2024-06-13 15:32:00 (99.0 MB/s) - ‘/content/SemNov_AML_DAAI_23-24/3D_OS_release_data/tmp_ScanObjectNN.tar’ saved [2623662080/2623662080]\n",
            "\n",
            "============\n",
            "Finished\n"
          ]
        }
      ],
      "source": [
        "!sh download_data.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ivADiRusxKL1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import h5py\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import sample\n",
        "from tqdm import tqdm\n",
        "from mpl_toolkits.mplot3d import proj3d\n",
        "from sklearn.metrics import roc_curve\n",
        "from notebooks.utils import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SR1 = {\n",
        "    4: 0,  # chair\n",
        "    8: 1,  # shelf\n",
        "    7: 2,  # door\n",
        "    12: 3,  # sink\n",
        "    13: 4  # sofa\n",
        "}\n",
        "\n",
        "SR2 = {\n",
        "    10: 0,  # bed\n",
        "    14: 1,  # toilet\n",
        "    5: 2,  # desk\n",
        "    6: 3,  # display\n",
        "    9: 2  # table\n",
        "}\n",
        "\n",
        "SR3 = {\n",
        "    0: 404,  # bag\n",
        "    1: 404,  # bin\n",
        "    2: 404,  # box\n",
        "    3: 404,  # cabinet\n",
        "    11: 404  # pillow\n",
        "}\n",
        "\n",
        "test_file = h5py.File('3D_OS_release_data/ScanObjectNN/h5_files/main_split/test_objectdataset.h5', 'r')\n",
        "train_file = h5py.File('3D_OS_release_data/ScanObjectNN/h5_files/main_split/training_objectdataset.h5', 'r')\n",
        "\n",
        "test_labels  = test_file['label'][:]\n",
        "train_labels = train_file['label'][:]\n",
        "\n",
        "test_clouds = test_file['data'][:]\n",
        "train_clouds = train_file['data'][:]\n",
        "\n",
        "all_labels = np.hstack((train_labels, test_labels))\n",
        "all_clouds = np.vstack((train_clouds, test_clouds))\n",
        "\n",
        "SR1_indices = [index for index, value in enumerate(all_labels) if value in SR1.keys()]\n",
        "SR2_indices = [index for index, value in enumerate(all_labels) if value in SR2.keys()]\n",
        "SR3_indices = [index for index, value in enumerate(all_labels) if value in SR3.keys()]\n",
        "\n",
        "SR1_clouds = all_clouds[SR1_indices]\n",
        "SR2_clouds = all_clouds[SR2_indices]\n",
        "SR3_clouds = all_clouds[SR3_indices]\n",
        "\n",
        "SR1_labels = [SR1[label] for label in all_labels[SR1_indices]]\n",
        "SR2_labels = [SR2[label] for label in all_labels[SR2_indices]]\n",
        "SR3_labels = [404 for _ in SR3_indices]\n",
        "\n",
        "all_indices = np.hstack((SR1_indices, SR2_indices, SR3_indices))\n",
        "all_labels = all_labels[all_indices]"
      ],
      "metadata": {
        "id": "xPRycllkZIyg"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PointNet++"
      ],
      "metadata": {
        "id": "izaFn3KRoCf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SR1"
      ],
      "metadata": {
        "id": "_SaNR7NyoCf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_NAME = 'PN2_CE_SR1'\n",
        "SRC = SR1_labels\n",
        "TAR1 = SR2_labels\n",
        "TAR2 = SR3_labels\n",
        "lab_to_text = lab_to_text_sr1"
      ],
      "metadata": {
        "id": "dyNOmDuSoCf8"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Discriminative method"
      ],
      "metadata": {
        "id": "6lILvmMnoCf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### DISCRIMINATIVE - setup\n",
        "src_logits = load_from_file(f'outputs/tensors/{DATA_NAME}/src_logits.pt')\n",
        "tar1_logits = load_from_file(f'outputs/tensors/{DATA_NAME}/tar1_logits.pt')\n",
        "tar2_logits = load_from_file(f'outputs/tensors/{DATA_NAME}/tar2_logits.pt')\n",
        "\n",
        "src_MSP_scores, src_MSP_pred = F.softmax(src_logits, dim=1).max(1)\n",
        "tar1_MSP_scores, tar1_MSP_pred = F.softmax(tar1_logits, dim=1).max(1)\n",
        "tar2_MSP_scores, tar2_MSP_pred = F.softmax(tar2_logits, dim=1).max(1)"
      ],
      "metadata": {
        "id": "d0OvgNimoCf8"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set OOD labels/truth\n",
        "src_labels = torch.tensor(SRC)\n",
        "tar1_labels = torch.tensor(np.full_like(TAR1, 404))\n",
        "tar2_labels = torch.tensor(np.full_like(TAR2, 404))"
      ],
      "metadata": {
        "id": "4SIZipoZoCf8"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "MGRhrwK_oCf8"
      },
      "outputs": [],
      "source": [
        "scores_MSP = torch.hstack((src_MSP_scores, tar1_MSP_scores, tar2_MSP_scores))\n",
        "preds_MSP = torch.hstack((src_MSP_pred, tar1_MSP_pred, tar2_MSP_pred))\n",
        "truth = torch.hstack((src_labels, tar1_labels, tar2_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ACCURACY_CHECK\n",
        "acc = 0\n",
        "for i in range(len(SRC)):\n",
        "  if truth[i] == preds_MSP[i]:\n",
        "    acc += 1\n",
        "\n",
        "print(acc/len(SRC))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb97aa9d-b125-47c7-e6ba-c17609e17312",
        "id": "dphYuz8BoCf9"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7880478087649403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIND THE THRESHOLD FOR 95 TPR\n",
        "ood_truth = torch.from_numpy(np.hstack((np.ones_like(src_labels), np.zeros_like(tar1_labels), np.zeros_like(tar2_labels))))\n",
        "\n",
        "fpr, tpr, thr = roc_curve(ood_truth, scores_MSP, pos_label=1)\n",
        "\n",
        "for i in range(len(tpr)-1, 0, -1):\n",
        "  if tpr[i] < 0.95:\n",
        "    break\n",
        "\n",
        "print(\"FPR at 95:\", fpr[i])\n",
        "threshold = thr[i+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ece8b9-5345-4c5f-a4be-de4c2ae2a48b",
        "id": "8ndZ9UheoCf9"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPR at 95: 0.8048929663608563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = list()\n",
        "wrong = list()\n",
        "preds = list()\n",
        "fp = 0\n",
        "\n",
        "for i in range(len(truth)):\n",
        "  pred = preds_MSP[i]\n",
        "  if scores_MSP[i] < threshold:\n",
        "    pred = torch.tensor(404)\n",
        "  if pred == truth[i]:\n",
        "    correct.append(i)\n",
        "  else:\n",
        "    wrong.append(i)\n",
        "    if truth[i] == torch.tensor(404): # false positive\n",
        "      fp += 1\n",
        "  preds.append(pred)\n",
        "\n",
        "print(\"Correctly classified\", len(correct), \"samples.\",\n",
        "      \"\\nMisclassified\", len(wrong), \"samples.\",\n",
        "      \"\\nFPR:\", fp/(len(truth) - len(src_labels)))  # sanity check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a087184-3752-4383-ac8f-5fdc343b206d",
        "id": "0-xLjpsIoCf9"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctly classified 1287 samples. \n",
            "Misclassified 1603 samples. \n",
            "FPR: 0.8048929663608563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_FOLDER = 'outputs/classification_results'\n",
        "if not os.path.exists(f'{OUTPUT_FOLDER}/{DATA_NAME}/MSP'):\n",
        "  os.makedirs(f'{OUTPUT_FOLDER}/{DATA_NAME}/MSP')\n",
        "\n",
        "for sample in tqdm(range(len(truth))):\n",
        "  title = f\"{lab_to_text[truth[sample].item()]}-{lab_to_text[preds[sample].item()]}\"\n",
        "  file = open(f'{OUTPUT_FOLDER}/{DATA_NAME}/MSP/{title}.txt', 'a+')\n",
        "  file.write(str(sample)+'\\n')\n",
        "  file.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdd4f37c-e62e-4ee2-d9cb-1af919acafe4",
        "id": "paFyOw9WoCf9"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2890/2890 [00:00<00:00, 11575.80it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distance based method"
      ],
      "metadata": {
        "id": "cHLt8Bx3oCf9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "iusXjiiToCf9"
      },
      "outputs": [],
      "source": [
        "##### DISTANCE BASED - setup\n",
        "\n",
        "train_labels = load_from_file(f\"outputs/tensors/{DATA_NAME}/train_labels.pt\")\n",
        "src_feats = load_from_file(f'outputs/feats/{DATA_NAME}.pt')\n",
        "\n",
        "src_dist = load_from_file(f'outputs/tensors/{DATA_NAME}/src_dist.pt')\n",
        "src_ids = load_from_file(f'outputs/tensors/{DATA_NAME}/src_ids.pt')\n",
        "tar1_dist = load_from_file(f'outputs/tensors/{DATA_NAME}/tar1_dist.pt')\n",
        "tar1_ids = load_from_file(f'outputs/tensors/{DATA_NAME}/tar1_ids.pt')\n",
        "tar2_dist = load_from_file(f'outputs/tensors/{DATA_NAME}/tar2_dist.pt')\n",
        "tar2_ids = load_from_file(f'outputs/tensors/{DATA_NAME}/tar2_ids.pt')\n",
        "\n",
        "src_L2_dist = src_dist.squeeze().cpu()\n",
        "src_L2_ids = src_ids.squeeze().cpu()  # index of nearest training sample\n",
        "src_L2_scores = 1 / src_dist\n",
        "\n",
        "tar1_L2_dist = tar1_dist.squeeze().cpu()\n",
        "tar1_L2_ids = tar1_ids.squeeze().cpu()  # index of nearest training sample\n",
        "tar1_L2_scores = 1 / tar1_dist\n",
        "\n",
        "tar2_L2_dist = tar2_dist.squeeze().cpu()\n",
        "tar2_L2_ids = tar2_ids.squeeze().cpu()  # index of nearest training sample\n",
        "tar2_L2_scores = 1 / tar2_dist\n",
        "\n",
        "\n",
        "# set OOD labels/truth\n",
        "src_labels = torch.tensor(SRC)\n",
        "tar1_labels = torch.tensor(np.full_like(TAR1, 404))\n",
        "tar2_labels = torch.tensor(np.full_like(TAR2, 404))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "aveDsMVsoCf-"
      },
      "outputs": [],
      "source": [
        "# train truth\n",
        "src_L2_pred = torch.from_numpy(train_labels[src_ids])\n",
        "tar1_L2_pred = torch.from_numpy(train_labels[tar1_ids])\n",
        "tar2_L2_pred = torch.from_numpy(train_labels[tar2_ids])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "EHe57S4yoCf-"
      },
      "outputs": [],
      "source": [
        "scores_L2 = torch.hstack((src_L2_scores, tar1_L2_scores, tar2_L2_scores))\n",
        "preds_L2 = torch.hstack((src_L2_pred, tar1_L2_pred, tar2_L2_pred))\n",
        "truth = torch.hstack((src_labels, tar1_labels, tar2_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIND THE THRESHOLD FOR 95 TPR\n",
        "ood_truth = torch.from_numpy(np.hstack((np.ones_like(src_labels), np.zeros_like(tar1_labels), np.zeros_like(tar2_labels))))\n",
        "\n",
        "fpr, tpr, thr = roc_curve(ood_truth, scores_L2, pos_label=1)\n",
        "\n",
        "for i in range(len(tpr)-1, 0, -1):\n",
        "  if tpr[i] < 0.95:\n",
        "    break\n",
        "\n",
        "print(\"FPR at 95:\", fpr[i])\n",
        "threshold = thr[i+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "284b20e9-cf05-4ccd-cc22-6a5997df4151",
        "id": "B5ca4b59oCf-"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPR at 95: 0.8379204892966361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ACCURACY_CHECK\n",
        "acc = 0\n",
        "for i in range(len(SRC)):\n",
        "  if truth[i] == preds_L2[i]:\n",
        "    acc += 1\n",
        "\n",
        "print(acc/len(SRC))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b696b81d-daa1-4470-c082-283c1fe3fd21",
        "id": "5Etnig96oCf-"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7800796812749003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = list()\n",
        "wrong = list()\n",
        "preds = list()\n",
        "fp = 0\n",
        "\n",
        "for i in range(len(truth)):\n",
        "  pred = preds_L2[i]\n",
        "  if scores_L2[i] < threshold:\n",
        "    pred = torch.tensor(404)\n",
        "  if pred == truth[i]:\n",
        "    correct.append(i)\n",
        "  else:\n",
        "    wrong.append(i)\n",
        "    if truth[i] == torch.tensor(404): # false positive\n",
        "      fp += 1\n",
        "  preds.append(pred)\n",
        "\n",
        "print(\"Correctly classified\", len(correct), \"samples.\",\n",
        "      \"\\nMisclassified\", len(wrong), \"samples.\",\n",
        "      \"\\nFPR:\", fp/(len(truth) - len(src_labels)))  # sanity check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edba4ff1-c2ef-4317-8c3b-613993d90798",
        "id": "0QxBJDbBoCf-"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctly classified 1223 samples. \n",
            "Misclassified 1667 samples. \n",
            "FPR: 0.8379204892966361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_FOLDER = 'outputs/classification_results'\n",
        "if not os.path.exists(f'{OUTPUT_FOLDER}/{DATA_NAME}/L2'):\n",
        "  os.makedirs(f'{OUTPUT_FOLDER}/{DATA_NAME}/L2')\n",
        "\n",
        "for sample in tqdm(range(len(truth))):\n",
        "  title = f\"{lab_to_text[truth[sample].item()]}-{lab_to_text[preds[sample].item()]}\"\n",
        "  file = open(f'{OUTPUT_FOLDER}/{DATA_NAME}/L2/{title}.txt', 'a+')\n",
        "  file.write(str(sample)+'\\n')\n",
        "  file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56c044ff-dd31-49e4-8e0a-2cec73d9e865",
        "id": "XQyM-fJAoCf-"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2890/2890 [00:00<00:00, 13760.15it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SR2"
      ],
      "metadata": {
        "id": "6m8OvT5ToCf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_NAME = 'PN2_CE_SR2'\n",
        "SRC = SR2_labels\n",
        "TAR1 = SR1_labels\n",
        "TAR2 = SR3_labels\n",
        "lab_to_text = lab_to_text_sr2"
      ],
      "metadata": {
        "id": "R5ETmuW8oCf_"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Discriminative method"
      ],
      "metadata": {
        "id": "WAjZ329foCf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### DISCRIMINATIVE - setup\n",
        "src_logits = load_from_file(f'outputs/tensors/{DATA_NAME}/src_logits.pt')\n",
        "tar1_logits = load_from_file(f'outputs/tensors/{DATA_NAME}/tar1_logits.pt')\n",
        "tar2_logits = load_from_file(f'outputs/tensors/{DATA_NAME}/tar2_logits.pt')\n",
        "\n",
        "src_MSP_scores, src_MSP_pred = F.softmax(src_logits, dim=1).max(1)\n",
        "tar1_MSP_scores, tar1_MSP_pred = F.softmax(tar1_logits, dim=1).max(1)\n",
        "tar2_MSP_scores, tar2_MSP_pred = F.softmax(tar2_logits, dim=1).max(1)"
      ],
      "metadata": {
        "id": "4QFm1OtjoCf_"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set OOD labels/truth\n",
        "src_labels = torch.tensor(SRC)\n",
        "tar1_labels = torch.tensor(np.full_like(TAR1, 404))\n",
        "tar2_labels = torch.tensor(np.full_like(TAR2, 404))"
      ],
      "metadata": {
        "id": "3ZxO1S5QoCf_"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "QV0-z4mxoCf_"
      },
      "outputs": [],
      "source": [
        "scores_MSP = torch.hstack((src_MSP_scores, tar1_MSP_scores, tar2_MSP_scores))\n",
        "preds_MSP = torch.hstack((src_MSP_pred, tar1_MSP_pred, tar2_MSP_pred))\n",
        "truth = torch.hstack((src_labels, tar1_labels, tar2_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ACCURACY_CHECK\n",
        "acc = 0\n",
        "for i in range(len(SRC)):\n",
        "  if truth[i] == preds_MSP[i]:\n",
        "    acc += 1\n",
        "\n",
        "print(acc/len(SRC))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90db4e97-9c09-4c8f-e4c9-896c3bd651ff",
        "id": "fPpNlSA8oCf_"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8375634517766497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIND THE THRESHOLD FOR 95 TPR\n",
        "ood_truth = torch.from_numpy(np.hstack((np.ones_like(src_labels), np.zeros_like(tar1_labels), np.zeros_like(tar2_labels))))\n",
        "\n",
        "fpr, tpr, thr = roc_curve(ood_truth, scores_MSP, pos_label=1)\n",
        "\n",
        "for i in range(len(tpr)-1, 0, -1):\n",
        "  if tpr[i] < 0.95:\n",
        "    break\n",
        "\n",
        "print(\"FPR at 95:\", fpr[i])\n",
        "threshold = thr[i+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b342f3-0816-4022-c521-92d4cbfceb55",
        "id": "bzIawSRWoCf_"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPR at 95: 0.8691722169362512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = list()\n",
        "wrong = list()\n",
        "preds = list()\n",
        "fp = 0\n",
        "\n",
        "for i in range(len(truth)):\n",
        "  pred = preds_MSP[i]\n",
        "  if scores_MSP[i] < threshold:\n",
        "    pred = torch.tensor(404)\n",
        "  if pred == truth[i]:\n",
        "    correct.append(i)\n",
        "  else:\n",
        "    wrong.append(i)\n",
        "    if truth[i] == torch.tensor(404): # false positive\n",
        "      fp += 1\n",
        "  preds.append(pred)\n",
        "\n",
        "print(\"Correctly classified\", len(correct), \"samples.\",\n",
        "      \"\\nMisclassified\", len(wrong), \"samples.\",\n",
        "      \"\\nFPR:\", fp/(len(truth) - len(src_labels)))  # sanity check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5ff615d-ff75-41f8-efb6-719340a04b16",
        "id": "Vg4NpHOCoCgA"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctly classified 911 samples. \n",
            "Misclassified 1979 samples. \n",
            "FPR: 0.8691722169362512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_FOLDER = 'outputs/classification_results'\n",
        "if not os.path.exists(f'{OUTPUT_FOLDER}/{DATA_NAME}/MSP'):\n",
        "  os.makedirs(f'{OUTPUT_FOLDER}/{DATA_NAME}/MSP')\n",
        "\n",
        "for sample in tqdm(range(len(truth))):\n",
        "  title = f\"{lab_to_text[truth[sample].item()]}-{lab_to_text[preds[sample].item()]}\"\n",
        "  file = open(f'{OUTPUT_FOLDER}/{DATA_NAME}/MSP/{title}.txt', 'a+')\n",
        "  file.write(str(sample)+'\\n')\n",
        "  file.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d8b3bd-887b-44a9-ba41-44bc07c92368",
        "id": "F0hj_zjDoCgA"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2890/2890 [00:00<00:00, 18935.53it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distance based method"
      ],
      "metadata": {
        "id": "gjMOZ6MxoCgA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "3WJkP0Y-oCgA"
      },
      "outputs": [],
      "source": [
        "##### DISTANCE BASED - setup\n",
        "\n",
        "train_labels = load_from_file(f\"outputs/tensors/{DATA_NAME}/train_labels.pt\")\n",
        "src_feats = load_from_file(f'outputs/feats/{DATA_NAME}.pt')\n",
        "\n",
        "src_dist = load_from_file(f'outputs/tensors/{DATA_NAME}/src_dist.pt')\n",
        "src_ids = load_from_file(f'outputs/tensors/{DATA_NAME}/src_ids.pt')\n",
        "tar1_dist = load_from_file(f'outputs/tensors/{DATA_NAME}/tar1_dist.pt')\n",
        "tar1_ids = load_from_file(f'outputs/tensors/{DATA_NAME}/tar1_ids.pt')\n",
        "tar2_dist = load_from_file(f'outputs/tensors/{DATA_NAME}/tar2_dist.pt')\n",
        "tar2_ids = load_from_file(f'outputs/tensors/{DATA_NAME}/tar2_ids.pt')\n",
        "\n",
        "src_L2_dist = src_dist.squeeze().cpu()\n",
        "src_L2_ids = src_ids.squeeze().cpu()  # index of nearest training sample\n",
        "src_L2_scores = 1 / src_dist\n",
        "\n",
        "tar1_L2_dist = tar1_dist.squeeze().cpu()\n",
        "tar1_L2_ids = tar1_ids.squeeze().cpu()  # index of nearest training sample\n",
        "tar1_L2_scores = 1 / tar1_dist\n",
        "\n",
        "tar2_L2_dist = tar2_dist.squeeze().cpu()\n",
        "tar2_L2_ids = tar2_ids.squeeze().cpu()  # index of nearest training sample\n",
        "tar2_L2_scores = 1 / tar2_dist\n",
        "\n",
        "\n",
        "# set OOD labels/truth\n",
        "src_labels = torch.tensor(SRC)\n",
        "tar1_labels = torch.tensor(np.full_like(TAR1, 404))\n",
        "tar2_labels = torch.tensor(np.full_like(TAR2, 404))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "OQZJmc8NoCgA"
      },
      "outputs": [],
      "source": [
        "# train truth\n",
        "src_L2_pred = torch.from_numpy(train_labels[src_L2_ids])\n",
        "tar1_L2_pred = torch.from_numpy(train_labels[tar1_L2_ids])\n",
        "tar2_L2_pred = torch.from_numpy(train_labels[tar2_L2_ids])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "XOS6fxyBoCgA"
      },
      "outputs": [],
      "source": [
        "scores_L2 = torch.hstack((src_L2_scores, tar1_L2_scores, tar2_L2_scores))\n",
        "preds_L2 = torch.hstack((src_L2_pred, tar1_L2_pred, tar2_L2_pred))\n",
        "truth = torch.hstack((src_labels, tar1_labels, tar2_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIND THE THRESHOLD FOR 95 TPR\n",
        "ood_truth = torch.from_numpy(np.hstack((np.ones_like(src_labels), np.zeros_like(tar1_labels), np.zeros_like(tar2_labels))))\n",
        "\n",
        "fpr, tpr, thr = roc_curve(ood_truth, scores_L2, pos_label=1)\n",
        "\n",
        "for i in range(len(tpr)-1, 0, -1):\n",
        "  if tpr[i] < 0.95:\n",
        "    break\n",
        "\n",
        "print(\"FPR at 95:\", fpr[i])\n",
        "threshold = thr[i+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a3700c-33ae-4b39-cd2e-dee147399afd",
        "id": "lAkpsrfqoCgA"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPR at 95: 0.807802093244529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ACCURACY_CHECK\n",
        "acc = 0\n",
        "for i in range(len(SRC)):\n",
        "  if truth[i] == preds_L2[i]:\n",
        "    acc += 1\n",
        "\n",
        "print(acc/len(SRC))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96a62563-474a-46a4-fdc0-6462917cb8d6",
        "id": "YHvlE7CVoCgA"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8362944162436549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = list()\n",
        "wrong = list()\n",
        "preds = list()\n",
        "fp = 0\n",
        "\n",
        "for i in range(len(truth)):\n",
        "  pred = preds_L2[i]\n",
        "  if scores_L2[i] < threshold:\n",
        "    pred = torch.tensor(404)\n",
        "  if pred == truth[i]:\n",
        "    correct.append(i)\n",
        "  else:\n",
        "    wrong.append(i)\n",
        "    if truth[i] == torch.tensor(404): # false positive\n",
        "      fp += 1\n",
        "  preds.append(pred)\n",
        "\n",
        "print(\"Correctly classified\", len(correct), \"samples.\",\n",
        "      \"\\nMisclassified\", len(wrong), \"samples.\",\n",
        "      \"\\nFPR:\", fp/(len(truth) - len(src_labels)))  # sanity check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "583400e9-66b0-4d93-b4ae-0fcf83af3236",
        "id": "FtJbXIA9oCgB"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctly classified 1041 samples. \n",
            "Misclassified 1849 samples. \n",
            "FPR: 0.807802093244529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_FOLDER = 'outputs/classification_results'\n",
        "if not os.path.exists(f'{OUTPUT_FOLDER}/{DATA_NAME}/L2'):\n",
        "  os.makedirs(f'{OUTPUT_FOLDER}/{DATA_NAME}/L2')\n",
        "\n",
        "for sample in tqdm(range(len(truth))):\n",
        "  title = f\"{lab_to_text[truth[sample].item()]}-{lab_to_text[preds[sample].item()]}\"\n",
        "  file = open(f'{OUTPUT_FOLDER}/{DATA_NAME}/L2/{title}.txt', 'a+')\n",
        "  file.write(str(sample)+'\\n')\n",
        "  file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34b19316-9278-4bdf-fd08-52b6c68a4a0b",
        "id": "Ha2wk6KkoCgB"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2890/2890 [00:00<00:00, 13512.40it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DGCNN"
      ],
      "metadata": {
        "id": "NwE7GQffUzdJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SR1"
      ],
      "metadata": {
        "id": "-AUeaNECnbS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_NAME = 'DGCNN_CE_SR1'\n",
        "SRC = SR1_labels\n",
        "TAR1 = SR2_labels\n",
        "TAR2 = SR3_labels\n",
        "lab_to_text = lab_to_text_sr1"
      ],
      "metadata": {
        "id": "3BToTC0QnbS9"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Discriminative method"
      ],
      "metadata": {
        "id": "n7Z0L8YknbS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### DISCRIMINATIVE - setup\n",
        "src_logits = load_from_file(f'outputs/tensors/{DATA_NAME}/src_logits.pt')\n",
        "tar1_logits = load_from_file(f'outputs/tensors/{DATA_NAME}/tar1_logits.pt')\n",
        "tar2_logits = load_from_file(f'outputs/tensors/{DATA_NAME}/tar2_logits.pt')\n",
        "\n",
        "src_MSP_scores, src_MSP_pred = F.softmax(src_logits, dim=1).max(1)\n",
        "tar1_MSP_scores, tar1_MSP_pred = F.softmax(tar1_logits, dim=1).max(1)\n",
        "tar2_MSP_scores, tar2_MSP_pred = F.softmax(tar2_logits, dim=1).max(1)"
      ],
      "metadata": {
        "id": "0UnUcRBznbS9"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set OOD labels/truth\n",
        "src_labels = torch.tensor(SRC)\n",
        "tar1_labels = torch.tensor(np.full_like(TAR1, 404))\n",
        "tar2_labels = torch.tensor(np.full_like(TAR2, 404))"
      ],
      "metadata": {
        "id": "YaUnWpSwnbS9"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "WV1g0BqAnbS9"
      },
      "outputs": [],
      "source": [
        "scores_MSP = torch.hstack((src_MSP_scores, tar1_MSP_scores, tar2_MSP_scores))\n",
        "preds_MSP = torch.hstack((src_MSP_pred, tar1_MSP_pred, tar2_MSP_pred))\n",
        "truth = torch.hstack((src_labels, tar1_labels, tar2_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ACCURACY_CHECK\n",
        "acc = 0\n",
        "for i in range(len(SRC)):\n",
        "  if truth[i] == preds_MSP[i]:\n",
        "    acc += 1\n",
        "\n",
        "print(acc/len(SRC))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "177407f5-9565-40b1-c01a-58fa669d6ec2",
        "id": "oIuF8KXrnbS-"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7243027888446215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIND THE THRESHOLD FOR 95 TPR\n",
        "ood_truth = torch.from_numpy(np.hstack((np.ones_like(src_labels), np.zeros_like(tar1_labels), np.zeros_like(tar2_labels))))\n",
        "\n",
        "fpr, tpr, thr = roc_curve(ood_truth, scores_MSP, pos_label=1)\n",
        "\n",
        "for i in range(len(tpr)-1, 0, -1):\n",
        "  if tpr[i] < 0.95:\n",
        "    break\n",
        "\n",
        "print(\"FPR at 95:\", fpr[i])\n",
        "threshold = thr[i+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4db6d29-dd45-4cf1-906d-18964b575b05",
        "id": "GamI2OOwnbS-"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPR at 95: 0.9015290519877676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = list()\n",
        "wrong = list()\n",
        "preds = list()\n",
        "fp = 0\n",
        "\n",
        "for i in range(len(truth)):\n",
        "  pred = preds_MSP[i]\n",
        "  if scores_MSP[i] < threshold:\n",
        "    pred = torch.tensor(404)\n",
        "  if pred == truth[i]:\n",
        "    correct.append(i)\n",
        "  else:\n",
        "    wrong.append(i)\n",
        "    if truth[i] == torch.tensor(404): # false positive\n",
        "      fp += 1\n",
        "  preds.append(pred)\n",
        "\n",
        "print(\"Correctly classified\", len(correct), \"samples.\",\n",
        "      \"\\nMisclassified\", len(wrong), \"samples.\",\n",
        "      \"\\nFPR:\", fp/(len(truth) - len(src_labels)))  # sanity check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34c56460-b4c7-411a-dfda-2974ac7e7e44",
        "id": "83RSfjf3nbS-"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctly classified 1047 samples. \n",
            "Misclassified 1843 samples. \n",
            "FPR: 0.9015290519877676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_FOLDER = 'outputs/classification_results'\n",
        "if not os.path.exists(f'{OUTPUT_FOLDER}/{DATA_NAME}/MSP'):\n",
        "  os.makedirs(f'{OUTPUT_FOLDER}/{DATA_NAME}/MSP')\n",
        "\n",
        "for sample in tqdm(range(len(truth))):\n",
        "  title = f\"{lab_to_text[truth[sample].item()]}-{lab_to_text[preds[sample].item()]}\"\n",
        "  file = open(f'{OUTPUT_FOLDER}/{DATA_NAME}/MSP/{title}.txt', 'a+')\n",
        "  file.write(str(sample)+'\\n')\n",
        "  file.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91807b36-7f1e-4fcd-f7ca-ef73fffbf8ac",
        "id": "JIG4LLHBnbS_"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2890/2890 [00:00<00:00, 14038.92it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distance based method"
      ],
      "metadata": {
        "id": "ABHkmT7rnbS_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "Tl-ztmKknbS_"
      },
      "outputs": [],
      "source": [
        "##### DISTANCE BASED - setup\n",
        "\n",
        "train_labels = load_from_file(f\"outputs/tensors/{DATA_NAME}/train_labels.pt\")\n",
        "src_feats = load_from_file(f'outputs/feats/{DATA_NAME}.pt')\n",
        "\n",
        "src_dist = load_from_file(f'outputs/tensors/{DATA_NAME}/src_dist.pt')\n",
        "src_ids = load_from_file(f'outputs/tensors/{DATA_NAME}/src_ids.pt')\n",
        "tar1_dist = load_from_file(f'outputs/tensors/{DATA_NAME}/tar1_dist.pt')\n",
        "tar1_ids = load_from_file(f'outputs/tensors/{DATA_NAME}/tar1_ids.pt')\n",
        "tar2_dist = load_from_file(f'outputs/tensors/{DATA_NAME}/tar2_dist.pt')\n",
        "tar2_ids = load_from_file(f'outputs/tensors/{DATA_NAME}/tar2_ids.pt')\n",
        "\n",
        "src_L2_dist = src_dist.squeeze().cpu()\n",
        "src_L2_ids = src_ids.squeeze().cpu()  # index of nearest training sample\n",
        "src_L2_scores = 1 / src_dist\n",
        "\n",
        "tar1_L2_dist = tar1_dist.squeeze().cpu()\n",
        "tar1_L2_ids = tar1_ids.squeeze().cpu()  # index of nearest training sample\n",
        "tar1_L2_scores = 1 / tar1_dist\n",
        "\n",
        "tar2_L2_dist = tar2_dist.squeeze().cpu()\n",
        "tar2_L2_ids = tar2_ids.squeeze().cpu()  # index of nearest training sample\n",
        "tar2_L2_scores = 1 / tar2_dist\n",
        "\n",
        "\n",
        "# set OOD labels/truth\n",
        "src_labels = torch.tensor(SRC)\n",
        "tar1_labels = torch.tensor(np.full_like(TAR1, 404))\n",
        "tar2_labels = torch.tensor(np.full_like(TAR2, 404))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "OwCKAeZ1nbS_"
      },
      "outputs": [],
      "source": [
        "# train truth\n",
        "src_L2_pred = torch.from_numpy(train_labels[src_ids])\n",
        "tar1_L2_pred = torch.from_numpy(train_labels[tar1_ids])\n",
        "tar2_L2_pred = torch.from_numpy(train_labels[tar2_ids])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "FTL2L0xenbS_"
      },
      "outputs": [],
      "source": [
        "scores_L2 = torch.hstack((src_L2_scores, tar1_L2_scores, tar2_L2_scores))\n",
        "preds_L2 = torch.hstack((src_L2_pred, tar1_L2_pred, tar2_L2_pred))\n",
        "truth = torch.hstack((src_labels, tar1_labels, tar2_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIND THE THRESHOLD FOR 95 TPR\n",
        "ood_truth = torch.from_numpy(np.hstack((np.ones_like(src_labels), np.zeros_like(tar1_labels), np.zeros_like(tar2_labels))))\n",
        "\n",
        "fpr, tpr, thr = roc_curve(ood_truth, scores_L2, pos_label=1)\n",
        "\n",
        "for i in range(len(tpr)-1, 0, -1):\n",
        "  if tpr[i] < 0.95:\n",
        "    break\n",
        "\n",
        "print(\"FPR at 95:\", fpr[i])\n",
        "threshold = thr[i+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c621fc00-be14-407e-e33c-d32b9cc465d5",
        "id": "2hM64fQZnbTA"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPR at 95: 0.8538226299694189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ACCURACY_CHECK\n",
        "acc = 0\n",
        "for i in range(len(SRC)):\n",
        "  if truth[i] == preds_L2[i]:\n",
        "    acc += 1\n",
        "\n",
        "print(acc/len(SRC))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46786b05-3047-41a1-9fe6-011a23b6fe77",
        "id": "uW5PNJ_1nbTA"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7298804780876494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = list()\n",
        "wrong = list()\n",
        "preds = list()\n",
        "fp = 0\n",
        "\n",
        "for i in range(len(truth)):\n",
        "  pred = preds_L2[i]\n",
        "  if scores_L2[i] < threshold:\n",
        "    pred = torch.tensor(404)\n",
        "  if pred == truth[i]:\n",
        "    correct.append(i)\n",
        "  else:\n",
        "    wrong.append(i)\n",
        "    if truth[i] == torch.tensor(404): # false positive\n",
        "      fp += 1\n",
        "  preds.append(pred)\n",
        "\n",
        "print(\"Correctly classified\", len(correct), \"samples.\",\n",
        "      \"\\nMisclassified\", len(wrong), \"samples.\",\n",
        "      \"\\nFPR:\", fp/(len(truth) - len(src_labels)))  # sanity check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "655bbcc5-de1a-4c49-d7fe-37a3426962ba",
        "id": "vP3KCxsEnbTA"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctly classified 1125 samples. \n",
            "Misclassified 1765 samples. \n",
            "FPR: 0.8538226299694189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_FOLDER = 'outputs/classification_results'\n",
        "if not os.path.exists(f'{OUTPUT_FOLDER}/{DATA_NAME}/L2'):\n",
        "  os.makedirs(f'{OUTPUT_FOLDER}/{DATA_NAME}/L2')\n",
        "\n",
        "for sample in tqdm(range(len(truth))):\n",
        "  title = f\"{lab_to_text[truth[sample].item()]}-{lab_to_text[preds[sample].item()]}\"\n",
        "  file = open(f'{OUTPUT_FOLDER}/{DATA_NAME}/L2/{title}.txt', 'a+')\n",
        "  file.write(str(sample)+'\\n')\n",
        "  file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f728c97-f49a-4a38-b0b8-dfd33c08d81d",
        "id": "lS7nl1GznbTA"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2890/2890 [00:00<00:00, 13758.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SR2"
      ],
      "metadata": {
        "id": "Sni-BAX6U4_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_NAME = 'DGCNN_CE_SR2'\n",
        "SRC = SR2_labels\n",
        "TAR1 = SR1_labels\n",
        "TAR2 = SR3_labels\n",
        "lab_to_text = lab_to_text_sr2"
      ],
      "metadata": {
        "id": "KxvXEEUUVWpw"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Discriminative method"
      ],
      "metadata": {
        "id": "-BoYmHdMVDM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### DISCRIMINATIVE - setup\n",
        "src_logits = load_from_file(f'outputs/tensors/{DATA_NAME}/src_logits.pt')\n",
        "tar1_logits = load_from_file(f'outputs/tensors/{DATA_NAME}/tar1_logits.pt')\n",
        "tar2_logits = load_from_file(f'outputs/tensors/{DATA_NAME}/tar2_logits.pt')\n",
        "\n",
        "src_MSP_scores, src_MSP_pred = F.softmax(src_logits, dim=1).max(1)\n",
        "tar1_MSP_scores, tar1_MSP_pred = F.softmax(tar1_logits, dim=1).max(1)\n",
        "tar2_MSP_scores, tar2_MSP_pred = F.softmax(tar2_logits, dim=1).max(1)"
      ],
      "metadata": {
        "id": "BgRfzHY5Yu7D"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set OOD labels/truth\n",
        "src_labels = torch.tensor(SRC)\n",
        "tar1_labels = torch.tensor(np.full_like(TAR1, 404))\n",
        "tar2_labels = torch.tensor(np.full_like(TAR2, 404))"
      ],
      "metadata": {
        "id": "iySsxPMzdjh-"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "id": "FnFofdP6wy1l"
      },
      "outputs": [],
      "source": [
        "scores_MSP = torch.hstack((src_MSP_scores, tar1_MSP_scores, tar2_MSP_scores))\n",
        "preds_MSP = torch.hstack((src_MSP_pred, tar1_MSP_pred, tar2_MSP_pred))\n",
        "truth = torch.hstack((src_labels, tar1_labels, tar2_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ACCURACY_CHECK\n",
        "acc = 0\n",
        "for i in range(len(SRC)):\n",
        "  if truth[i] == preds_MSP[i]:\n",
        "    acc += 1\n",
        "\n",
        "print(acc/len(SRC))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajkqAT-2cL8f",
        "outputId": "3e38ce94-74a3-415e-e34f-e82d6365d53a"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6789340101522843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIND THE THRESHOLD FOR 95 TPR\n",
        "ood_truth = torch.from_numpy(np.hstack((np.ones_like(src_labels), np.zeros_like(tar1_labels), np.zeros_like(tar2_labels))))\n",
        "\n",
        "fpr, tpr, thr = roc_curve(ood_truth, scores_MSP, pos_label=1)\n",
        "\n",
        "for i in range(len(tpr)-1, 0, -1):\n",
        "  if tpr[i] < 0.95:\n",
        "    break\n",
        "\n",
        "print(\"FPR at 95:\", fpr[i])\n",
        "threshold = thr[i+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpKKAUZWfrRj",
        "outputId": "6408fb5a-f041-450f-a035-ad6f16a6a9a9"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPR at 95: 0.9005708848715509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = list()\n",
        "wrong = list()\n",
        "preds = list()\n",
        "fp = 0\n",
        "\n",
        "for i in range(len(truth)):\n",
        "  pred = preds_MSP[i]\n",
        "  if scores_MSP[i] < threshold:\n",
        "    pred = torch.tensor(404)\n",
        "  if pred == truth[i]:\n",
        "    correct.append(i)\n",
        "  else:\n",
        "    wrong.append(i)\n",
        "    if truth[i] == torch.tensor(404): # false positive\n",
        "      fp += 1\n",
        "  preds.append(pred)\n",
        "\n",
        "print(\"Correctly classified\", len(correct), \"samples.\",\n",
        "      \"\\nMisclassified\", len(wrong), \"samples.\",\n",
        "      \"\\nFPR:\", fp/(len(truth) - len(src_labels)))  # sanity check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRy6LUl_a-89",
        "outputId": "31482257-d738-4221-fe58-424a7ceaf937"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctly classified 731 samples. \n",
            "Misclassified 2159 samples. \n",
            "FPR: 0.9005708848715509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_FOLDER = 'outputs/classification_results'\n",
        "if not os.path.exists(f'{OUTPUT_FOLDER}/{DATA_NAME}/MSP'):\n",
        "  os.makedirs(f'{OUTPUT_FOLDER}/{DATA_NAME}/MSP')\n",
        "\n",
        "for sample in tqdm(range(len(truth))):\n",
        "  title = f\"{lab_to_text[truth[sample].item()]}-{lab_to_text[preds[sample].item()]}\"\n",
        "  file = open(f'{OUTPUT_FOLDER}/{DATA_NAME}/MSP/{title}.txt', 'a+')\n",
        "  file.write(str(sample)+'\\n')\n",
        "  file.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ5UrZ1Xjv_r",
        "outputId": "3d36e88b-254a-4c4d-d1ce-cf11931f362d"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2890/2890 [00:00<00:00, 14025.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distance based method"
      ],
      "metadata": {
        "id": "pXyXvnpkY8zE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "id": "kf2aiRQiwy1l"
      },
      "outputs": [],
      "source": [
        "##### DISTANCE BASED - setup\n",
        "\n",
        "train_labels = load_from_file(f\"outputs/tensors/{DATA_NAME}/train_labels.pt\")\n",
        "src_feats = load_from_file(f'outputs/feats/{DATA_NAME}.pt')\n",
        "\n",
        "src_dist = load_from_file(f'outputs/tensors/{DATA_NAME}/src_dist.pt')\n",
        "src_ids = load_from_file(f'outputs/tensors/{DATA_NAME}/src_ids.pt')\n",
        "tar1_dist = load_from_file(f'outputs/tensors/{DATA_NAME}/tar1_dist.pt')\n",
        "tar1_ids = load_from_file(f'outputs/tensors/{DATA_NAME}/tar1_ids.pt')\n",
        "tar2_dist = load_from_file(f'outputs/tensors/{DATA_NAME}/tar2_dist.pt')\n",
        "tar2_ids = load_from_file(f'outputs/tensors/{DATA_NAME}/tar2_ids.pt')\n",
        "\n",
        "src_L2_dist = src_dist.squeeze().cpu()\n",
        "src_L2_ids = src_ids.squeeze().cpu()  # index of nearest training sample\n",
        "src_L2_scores = 1 / src_dist\n",
        "\n",
        "tar1_L2_dist = tar1_dist.squeeze().cpu()\n",
        "tar1_L2_ids = tar1_ids.squeeze().cpu()  # index of nearest training sample\n",
        "tar1_L2_scores = 1 / tar1_dist\n",
        "\n",
        "tar2_L2_dist = tar2_dist.squeeze().cpu()\n",
        "tar2_L2_ids = tar2_ids.squeeze().cpu()  # index of nearest training sample\n",
        "tar2_L2_scores = 1 / tar2_dist\n",
        "\n",
        "\n",
        "# set OOD labels/truth\n",
        "src_labels = torch.tensor(SRC)\n",
        "tar1_labels = torch.tensor(np.full_like(TAR1, 404))\n",
        "tar2_labels = torch.tensor(np.full_like(TAR2, 404))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "id": "A6eUkHlpwy1m"
      },
      "outputs": [],
      "source": [
        "# train truth\n",
        "src_L2_pred = torch.from_numpy(train_labels[src_ids])\n",
        "tar1_L2_pred = torch.from_numpy(train_labels[tar1_ids])\n",
        "tar2_L2_pred = torch.from_numpy(train_labels[tar2_ids])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {
        "id": "SXeABcEPwy1m"
      },
      "outputs": [],
      "source": [
        "scores_L2 = torch.hstack((src_L2_scores, tar1_L2_scores, tar2_L2_scores))\n",
        "preds_L2 = torch.hstack((src_L2_pred, tar1_L2_pred, tar2_L2_pred))\n",
        "preds_L2 = torch.where(preds_L2==4, torch.tensor(2), preds_L2)\n",
        "truth = torch.hstack((src_labels, tar1_labels, tar2_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIND THE THRESHOLD FOR 95 TPR\n",
        "ood_truth = torch.from_numpy(np.hstack((np.ones_like(src_labels), np.zeros_like(tar1_labels), np.zeros_like(tar2_labels))))\n",
        "\n",
        "fpr, tpr, thr = roc_curve(ood_truth, scores_L2, pos_label=1)\n",
        "\n",
        "for i in range(len(tpr)-1, 0, -1):\n",
        "  if tpr[i] < 0.95:\n",
        "    break\n",
        "\n",
        "print(\"FPR at 95:\", fpr[i])\n",
        "threshold = thr[i+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6qgUP8KUIFQ",
        "outputId": "06a30766-e8cb-45a5-a350-881e76e09d55"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPR at 95: 0.8920076117982874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ACCURACY_CHECK\n",
        "acc = 0\n",
        "for i in range(len(SRC)):\n",
        "  if truth[i] == preds_L2[i]:\n",
        "    acc += 1\n",
        "\n",
        "print(acc/len(SRC))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCopQU0WkV_p",
        "outputId": "40863999-a459-4a32-c811-d7cf6cae30a1"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6979695431472082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = list()\n",
        "wrong = list()\n",
        "preds = list()\n",
        "fp = 0\n",
        "\n",
        "for i in range(len(truth)):\n",
        "  pred = preds_L2[i]\n",
        "  if scores_L2[i] < threshold:\n",
        "    pred = torch.tensor(404)\n",
        "  if pred == truth[i]:\n",
        "    correct.append(i)\n",
        "  else:\n",
        "    wrong.append(i)\n",
        "    if truth[i] == torch.tensor(404): # false positive\n",
        "      fp += 1\n",
        "  preds.append(pred)\n",
        "\n",
        "print(\"Correctly classified\", len(correct), \"samples.\",\n",
        "      \"\\nMisclassified\", len(wrong), \"samples.\",\n",
        "      \"\\nFPR:\", fp/(len(truth) - len(src_labels)))  # sanity check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3BjyDxkUbBX",
        "outputId": "ed29749c-2ef5-4a9e-dcc0-e55c852d6f4d"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctly classified 754 samples. \n",
            "Misclassified 2136 samples. \n",
            "FPR: 0.8920076117982874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_FOLDER = 'outputs/classification_results'\n",
        "if not os.path.exists(f'{OUTPUT_FOLDER}/{DATA_NAME}/L2'):\n",
        "  os.makedirs(f'{OUTPUT_FOLDER}/{DATA_NAME}/L2')\n",
        "\n",
        "for sample in tqdm(range(len(truth))):\n",
        "  title = f\"{lab_to_text[truth[sample].item()]}-{lab_to_text[preds[sample].item()]}\"\n",
        "  file = open(f'{OUTPUT_FOLDER}/{DATA_NAME}/L2/{title}.txt', 'a+')\n",
        "  file.write(str(sample)+'\\n')\n",
        "  file.close()"
      ],
      "metadata": {
        "id": "tNjjsHbuUhcv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57871e4e-b01a-4d21-f967-c026e1749c3d"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2890/2890 [00:00<00:00, 16237.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenShape"
      ],
      "metadata": {
        "id": "SCx1wmgRomWc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SR1"
      ],
      "metadata": {
        "id": "eAoxz5XXomWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_NAME = 'OpenShape_SR1'\n",
        "SRC = SR1_labels\n",
        "TAR1 = SR2_labels\n",
        "TAR2 = SR3_labels\n",
        "SRC_indices = SR1_indices\n",
        "TAR1_indices = SR2_indices\n",
        "TAR2_indices = SR3_indices\n",
        "lab_to_text = lab_to_text_sr1"
      ],
      "metadata": {
        "id": "-hUSBXrAomWi"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Discriminative method"
      ],
      "metadata": {
        "id": "ekoxgrufomWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### DISCRIMINATIVE - setup\n",
        "img_scores = load_from_file(f'outputs/tensors/{DATA_NAME}/img_scores.pt')\n",
        "txt_scores = load_from_file(f'outputs/tensors/{DATA_NAME}/text_scores.pt')\n",
        "\n",
        "openshape_scores = img_scores + txt_scores\n",
        "\n",
        "src_logits = torch.tensor(np.array([openshape_scores[i] for i in SRC_indices])).squeeze(1)\n",
        "tar1_logits = torch.tensor(np.array([openshape_scores[i] for i in TAR1_indices])).squeeze(1)\n",
        "tar2_logits = torch.tensor(np.array([openshape_scores[i] for i in TAR2_indices])).squeeze(1)\n",
        "\n",
        "src_MSP_scores, src_MSP_pred = src_logits.max(1)\n",
        "tar1_MSP_scores, tar1_MSP_pred = tar1_logits.max(1)\n",
        "tar2_MSP_scores, tar2_MSP_pred = tar2_logits.max(1)"
      ],
      "metadata": {
        "id": "WDbo3_FNomWj"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set OOD labels/truth\n",
        "src_labels = torch.tensor(SRC)\n",
        "tar1_labels = torch.tensor(np.full_like(TAR1, 404))\n",
        "tar2_labels = torch.tensor(np.full_like(TAR2, 404))"
      ],
      "metadata": {
        "id": "cK0hTqSlomWj"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "id": "kOWCDEYlomWj"
      },
      "outputs": [],
      "source": [
        "scores_MSP = torch.hstack((src_MSP_scores, tar1_MSP_scores, tar2_MSP_scores))\n",
        "preds_MSP = torch.hstack((src_MSP_pred, tar1_MSP_pred, tar2_MSP_pred))\n",
        "truth = torch.hstack((src_labels, tar1_labels, tar2_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ACCURACY_CHECK\n",
        "acc = 0\n",
        "for i in range(len(SRC)):\n",
        "  if truth[i] == preds_MSP[i]:\n",
        "    acc += 1\n",
        "\n",
        "print(acc/len(SRC))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14fa91da-fb2a-4398-fae4-445f954c45fa",
        "id": "l_BKLtBwomWj"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8589641434262948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIND THE THRESHOLD FOR 95 TPR\n",
        "ood_truth = torch.from_numpy(np.hstack((np.ones_like(src_labels), np.zeros_like(tar1_labels), np.zeros_like(tar2_labels))))\n",
        "\n",
        "fpr, tpr, thr = roc_curve(ood_truth, scores_MSP, pos_label=1)\n",
        "\n",
        "for i in range(len(tpr)-1, 0, -1):\n",
        "  if tpr[i] < 0.95:\n",
        "    break\n",
        "\n",
        "print(\"FPR at 95:\", fpr[i])\n",
        "threshold = thr[i+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b8e4a3-4135-4489-8c79-1df6a79c8abb",
        "id": "Ay134GgPomWk"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPR at 95: 0.6709480122324158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = list()\n",
        "wrong = list()\n",
        "preds = list()\n",
        "fp = 0\n",
        "\n",
        "for i in range(len(truth)):\n",
        "  pred = preds_MSP[i]\n",
        "  if scores_MSP[i] < threshold:\n",
        "    pred = torch.tensor(404)\n",
        "  if pred == truth[i]:\n",
        "    correct.append(i)\n",
        "  else:\n",
        "    wrong.append(i)\n",
        "    if truth[i] == torch.tensor(404): # false positive\n",
        "      fp += 1\n",
        "  preds.append(pred)\n",
        "\n",
        "print(\"Correctly classified\", len(correct), \"samples.\",\n",
        "      \"\\nMisclassified\", len(wrong), \"samples.\",\n",
        "      \"\\nFPR:\", fp/(len(truth) - len(src_labels)))  # sanity check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f930e4-c2b2-4b8f-bf01-f04f9863fe3e",
        "id": "D0gDZ1nPomWk"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctly classified 1583 samples. \n",
            "Misclassified 1307 samples. \n",
            "FPR: 0.6709480122324158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_FOLDER = 'outputs/classification_results'\n",
        "if not os.path.exists(f'{OUTPUT_FOLDER}/{DATA_NAME}/MSP'):\n",
        "  os.makedirs(f'{OUTPUT_FOLDER}/{DATA_NAME}/MSP')\n",
        "\n",
        "for sample in tqdm(range(len(truth))):\n",
        "  title = f\"{lab_to_text[truth[sample].item()]}-{lab_to_text[preds[sample].item()]}\"\n",
        "  file = open(f'{OUTPUT_FOLDER}/{DATA_NAME}/MSP/{title}.txt', 'a+')\n",
        "  file.write(str(sample)+'\\n')\n",
        "  file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f75d71c7-19ef-4950-e994-8ffa19217256",
        "id": "-dlpvJPFomWk"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2890/2890 [00:00<00:00, 23189.57it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distance based method"
      ],
      "metadata": {
        "id": "9PxBuRRhomWk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "id": "Iz_tLLOAomWk"
      },
      "outputs": [],
      "source": [
        "##### DISTANCE BASED - setup\n",
        "\n",
        "train_labels = load_from_file(f\"outputs/tensors/{DATA_NAME}/train_labels.pt\")\n",
        "\n",
        "src_dist = load_from_file(f'outputs/tensors/{DATA_NAME}/src_dist.pt')\n",
        "src_ids = load_from_file(f'outputs/tensors/{DATA_NAME}/src_ids.pt')\n",
        "tar1_dist = load_from_file(f'outputs/tensors/{DATA_NAME}/tar1_dist.pt')\n",
        "tar1_ids = load_from_file(f'outputs/tensors/{DATA_NAME}/tar1_ids.pt')\n",
        "tar2_dist = load_from_file(f'outputs/tensors/{DATA_NAME}/tar2_dist.pt')\n",
        "tar2_ids = load_from_file(f'outputs/tensors/{DATA_NAME}/tar2_ids.pt')\n",
        "\n",
        "src_L2_dist = src_dist.squeeze().cpu()\n",
        "src_L2_ids = src_ids.squeeze().cpu()  # index of nearest training sample\n",
        "src_L2_scores = 1 / src_dist\n",
        "\n",
        "tar1_L2_dist = tar1_dist.squeeze().cpu()\n",
        "tar1_L2_ids = tar1_ids.squeeze().cpu()  # index of nearest training sample\n",
        "tar1_L2_scores = 1 / tar1_dist\n",
        "\n",
        "tar2_L2_dist = tar2_dist.squeeze().cpu()\n",
        "tar2_L2_ids = tar2_ids.squeeze().cpu()  # index of nearest training sample\n",
        "tar2_L2_scores = 1 / tar2_dist\n",
        "\n",
        "\n",
        "# set OOD labels/truth\n",
        "src_labels = torch.tensor(SRC)\n",
        "tar1_labels = torch.tensor(np.full_like(TAR1, 404))\n",
        "tar2_labels = torch.tensor(np.full_like(TAR2, 404))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "p7JuHYbdomWk"
      },
      "outputs": [],
      "source": [
        "# train truth\n",
        "src_L2_pred = torch.from_numpy(train_labels[src_ids])\n",
        "tar1_L2_pred = torch.from_numpy(train_labels[tar1_ids])\n",
        "tar2_L2_pred = torch.from_numpy(train_labels[tar2_ids])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "mOwDQMb8omWl"
      },
      "outputs": [],
      "source": [
        "scores_L2 = torch.hstack((src_L2_scores, tar1_L2_scores, tar2_L2_scores))\n",
        "preds_L2 = torch.hstack((src_L2_pred, tar1_L2_pred, tar2_L2_pred))\n",
        "truth = torch.hstack((src_labels, tar1_labels, tar2_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIND THE THRESHOLD FOR 95 TPR\n",
        "ood_truth = torch.from_numpy(np.hstack((np.ones_like(src_labels), np.zeros_like(tar1_labels), np.zeros_like(tar2_labels))))\n",
        "\n",
        "fpr, tpr, thr = roc_curve(ood_truth, scores_L2, pos_label=1)\n",
        "\n",
        "for i in range(len(tpr)-1, 0, -1):\n",
        "  if tpr[i] < 0.95:\n",
        "    break\n",
        "\n",
        "print(\"FPR at 95:\", fpr[i])\n",
        "threshold = thr[i+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc89206f-d6db-4d22-fd9e-184fec99133f",
        "id": "zNFweduPomWl"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPR at 95: 0.8159021406727829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ACCURACY_CHECK\n",
        "acc = 0\n",
        "for i in range(len(SRC)):\n",
        "  if truth[i] == preds_L2[i]:\n",
        "    acc += 1\n",
        "\n",
        "print(acc/len(SRC))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed930e84-86fa-4fd2-bc53-0f59b3340708",
        "id": "a97ZpGphomWl"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9139442231075697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = list()\n",
        "wrong = list()\n",
        "preds = list()\n",
        "fp = 0\n",
        "\n",
        "for i in range(len(truth)):\n",
        "  pred = preds_L2[i]\n",
        "  if scores_L2[i] < threshold:\n",
        "    pred = torch.tensor(404)\n",
        "  if pred == truth[i]:\n",
        "    correct.append(i)\n",
        "  else:\n",
        "    wrong.append(i)\n",
        "    if truth[i] == torch.tensor(404): # false positive\n",
        "      fp += 1\n",
        "  preds.append(pred)\n",
        "\n",
        "print(\"Correctly classified\", len(correct), \"samples.\",\n",
        "      \"\\nMisclassified\", len(wrong), \"samples.\",\n",
        "      \"\\nFPR:\", fp/(len(truth) - len(src_labels)))  # sanity check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df5ecb2-f881-4845-bfdf-61c9726df762",
        "id": "0JPf1lnIomWl"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctly classified 1401 samples. \n",
            "Misclassified 1489 samples. \n",
            "FPR: 0.8159021406727829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_FOLDER = 'outputs/classification_results'\n",
        "if not os.path.exists(f'{OUTPUT_FOLDER}/{DATA_NAME}/L2'):\n",
        "  os.makedirs(f'{OUTPUT_FOLDER}/{DATA_NAME}/L2')\n",
        "\n",
        "for sample in tqdm(range(len(truth))):\n",
        "  title = f\"{lab_to_text[truth[sample].item()]}-{lab_to_text[preds[sample].item()]}\"\n",
        "  file = open(f'{OUTPUT_FOLDER}/{DATA_NAME}/L2/{title}.txt', 'a+')\n",
        "  file.write(str(sample)+'\\n')\n",
        "  file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65005c5c-ed9b-4046-9e16-4dc418f8abac",
        "id": "2j6uKlJhomWl"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2890/2890 [00:00<00:00, 24494.14it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SR2"
      ],
      "metadata": {
        "id": "bjW82v3PqYuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_NAME = 'OpenShape_SR2'\n",
        "SRC = SR2_labels\n",
        "TAR1 = SR1_labels\n",
        "TAR2 = SR3_labels\n",
        "SRC_indices = SR2_indices\n",
        "TAR1_indices = SR1_indices\n",
        "TAR2_indices = SR3_indices\n",
        "lab_to_text = lab_to_text_sr2"
      ],
      "metadata": {
        "id": "e6YEh2woqYue"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Discriminative method"
      ],
      "metadata": {
        "id": "pekTIntpqYue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### DISCRIMINATIVE - setup\n",
        "img_scores = load_from_file(f'outputs/tensors/{DATA_NAME}/img_scores.pt')\n",
        "txt_scores = load_from_file(f'outputs/tensors/{DATA_NAME}/text_scores.pt')\n",
        "\n",
        "openshape_scores = img_scores + txt_scores\n",
        "\n",
        "src_logits = torch.tensor(np.array([openshape_scores[i] for i in SRC_indices])).squeeze(1)\n",
        "tar1_logits = torch.tensor(np.array([openshape_scores[i] for i in TAR1_indices])).squeeze(1)\n",
        "tar2_logits = torch.tensor(np.array([openshape_scores[i] for i in TAR2_indices])).squeeze(1)\n",
        "\n",
        "# merge desk and table prediction into same class for SR2\n",
        "src_table = src_logits[:, 2] + src_logits[:, 4]\n",
        "tar1_table = tar1_logits[:, 2] + tar1_logits[:, 4]\n",
        "tar2_table = tar2_logits[:, 2] + tar2_logits[:, 4]\n",
        "\n",
        "src_logits = torch.cat((src_logits[:, :2], src_table.unsqueeze(1), src_logits[:, 3].unsqueeze(1)), dim=1)\n",
        "tar1_logits = torch.cat((tar1_logits[:, :2], tar1_table.unsqueeze(1), tar1_logits[:, 3].unsqueeze(1)), dim=1)\n",
        "tar2_logits = torch.cat((tar2_logits[:, :2], tar2_table.unsqueeze(1), tar2_logits[:, 3].unsqueeze(1)), dim=1)\n",
        "\n",
        "src_MSP_scores, src_MSP_pred = src_logits.max(1)\n",
        "tar1_MSP_scores, tar1_MSP_pred = tar1_logits.max(1)\n",
        "tar2_MSP_scores, tar2_MSP_pred = tar2_logits.max(1)"
      ],
      "metadata": {
        "id": "UUNUJ0xUqYue"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set OOD labels/truth\n",
        "src_labels = torch.tensor(SRC)\n",
        "tar1_labels = torch.tensor(np.full_like(TAR1, 404))\n",
        "tar2_labels = torch.tensor(np.full_like(TAR2, 404))"
      ],
      "metadata": {
        "id": "vtWrssUCqYue"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "id": "L0vacsDEqYue"
      },
      "outputs": [],
      "source": [
        "scores_MSP = torch.hstack((src_MSP_scores, tar1_MSP_scores, tar2_MSP_scores))\n",
        "preds_MSP = torch.hstack((src_MSP_pred, tar1_MSP_pred, tar2_MSP_pred))\n",
        "truth = torch.hstack((src_labels, tar1_labels, tar2_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ACCURACY_CHECK\n",
        "acc = 0\n",
        "for i in range(len(SRC)):\n",
        "  if truth[i] == preds_MSP[i]:\n",
        "    acc += 1\n",
        "\n",
        "print(acc/len(SRC))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "007ca933-e035-4fd3-de85-a27570ebe6c9",
        "id": "mryAorKnqYue"
      },
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5203045685279187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIND THE THRESHOLD FOR 95 TPR\n",
        "ood_truth = torch.from_numpy(np.hstack((np.ones_like(src_labels), np.zeros_like(tar1_labels), np.zeros_like(tar2_labels))))\n",
        "\n",
        "fpr, tpr, thr = roc_curve(ood_truth, scores_MSP, pos_label=1)\n",
        "\n",
        "for i in range(len(tpr)-1, 0, -1):\n",
        "  if tpr[i] < 0.95:\n",
        "    break\n",
        "\n",
        "print(\"FPR at 95:\", fpr[i])\n",
        "threshold = thr[i+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a163a5-be7e-4d53-f01c-6fb23c223c30",
        "id": "OoserSLrqYuf"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPR at 95: 0.9533777354900095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = list()\n",
        "wrong = list()\n",
        "preds = list()\n",
        "fp = 0\n",
        "\n",
        "for i in range(len(truth)):\n",
        "  pred = preds_MSP[i]\n",
        "  if scores_MSP[i] < threshold:\n",
        "    pred = torch.tensor(404)\n",
        "  if pred == truth[i]:\n",
        "    correct.append(i)\n",
        "  else:\n",
        "    wrong.append(i)\n",
        "    if truth[i] == torch.tensor(404): # false positive\n",
        "      fp += 1\n",
        "  preds.append(pred)\n",
        "\n",
        "print(\"Correctly classified\", len(correct), \"samples.\",\n",
        "      \"\\nMisclassified\", len(wrong), \"samples.\",\n",
        "      \"\\nFPR:\", fp/(len(truth) - len(src_labels)))  # sanity check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7004f750-8032-4348-8d43-e8bd166e7577",
        "id": "8TLPkyDDqYuf"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctly classified 501 samples. \n",
            "Misclassified 2389 samples. \n",
            "FPR: 0.9533777354900095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_FOLDER = 'outputs/classification_results'\n",
        "if not os.path.exists(f'{OUTPUT_FOLDER}/{DATA_NAME}/MSP'):\n",
        "  os.makedirs(f'{OUTPUT_FOLDER}/{DATA_NAME}/MSP')\n",
        "\n",
        "for sample in tqdm(range(len(truth))):\n",
        "  title = f\"{lab_to_text[truth[sample].item()]}-{lab_to_text[preds[sample].item()]}\"\n",
        "  file = open(f'{OUTPUT_FOLDER}/{DATA_NAME}/MSP/{title}.txt', 'a+')\n",
        "  file.write(str(sample)+'\\n')\n",
        "  file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f37a6ee-379c-4c22-a2d9-17485f364ffd",
        "id": "RqBrhFdFqYuf"
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2890/2890 [00:00<00:00, 22692.20it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distance based method"
      ],
      "metadata": {
        "id": "_C44XdYWqYuf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "id": "EHZ2B37KqYuf"
      },
      "outputs": [],
      "source": [
        "##### DISTANCE BASED - setup\n",
        "\n",
        "train_labels = load_from_file(f\"outputs/tensors/{DATA_NAME}/train_labels.pt\")\n",
        "\n",
        "src_dist = load_from_file(f'outputs/tensors/{DATA_NAME}/src_dist.pt')\n",
        "src_ids = load_from_file(f'outputs/tensors/{DATA_NAME}/src_ids.pt')\n",
        "tar1_dist = load_from_file(f'outputs/tensors/{DATA_NAME}/tar1_dist.pt')\n",
        "tar1_ids = load_from_file(f'outputs/tensors/{DATA_NAME}/tar1_ids.pt')\n",
        "tar2_dist = load_from_file(f'outputs/tensors/{DATA_NAME}/tar2_dist.pt')\n",
        "tar2_ids = load_from_file(f'outputs/tensors/{DATA_NAME}/tar2_ids.pt')\n",
        "\n",
        "src_L2_dist = src_dist.squeeze().cpu()\n",
        "src_L2_ids = src_ids.squeeze().cpu()  # index of nearest training sample\n",
        "src_L2_scores = 1 / src_dist\n",
        "\n",
        "tar1_L2_dist = tar1_dist.squeeze().cpu()\n",
        "tar1_L2_ids = tar1_ids.squeeze().cpu()  # index of nearest training sample\n",
        "tar1_L2_scores = 1 / tar1_dist\n",
        "\n",
        "tar2_L2_dist = tar2_dist.squeeze().cpu()\n",
        "tar2_L2_ids = tar2_ids.squeeze().cpu()  # index of nearest training sample\n",
        "tar2_L2_scores = 1 / tar2_dist\n",
        "\n",
        "\n",
        "# set OOD labels/truth\n",
        "src_labels = torch.tensor(SRC)\n",
        "tar1_labels = torch.tensor(np.full_like(TAR1, 404))\n",
        "tar2_labels = torch.tensor(np.full_like(TAR2, 404))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "id": "37gBKpaXqYug"
      },
      "outputs": [],
      "source": [
        "# train truth\n",
        "src_L2_pred = torch.from_numpy(train_labels[src_ids])\n",
        "tar1_L2_pred = torch.from_numpy(train_labels[tar1_ids])\n",
        "tar2_L2_pred = torch.from_numpy(train_labels[tar2_ids])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "id": "rrLy1I-5qYug"
      },
      "outputs": [],
      "source": [
        "scores_L2 = torch.hstack((src_L2_scores, tar1_L2_scores, tar2_L2_scores))\n",
        "preds_L2 = torch.hstack((src_L2_pred, tar1_L2_pred, tar2_L2_pred))\n",
        "truth = torch.hstack((src_labels, tar1_labels, tar2_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIND THE THRESHOLD FOR 95 TPR\n",
        "ood_truth = torch.from_numpy(np.hstack((np.ones_like(src_labels), np.zeros_like(tar1_labels), np.zeros_like(tar2_labels))))\n",
        "\n",
        "fpr, tpr, thr = roc_curve(ood_truth, scores_L2, pos_label=1)\n",
        "\n",
        "for i in range(len(tpr)-1, 0, -1):\n",
        "  if tpr[i] < 0.95:\n",
        "    break\n",
        "\n",
        "print(\"FPR at 95:\", fpr[i])\n",
        "threshold = thr[i+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5392e3f-0736-4777-fadc-820279ac5064",
        "id": "BDuJu4xqqYug"
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPR at 95: 0.8810656517602283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ACCURACY_CHECK\n",
        "acc = 0\n",
        "for i in range(len(SRC)):\n",
        "  if truth[i] == preds_L2[i]:\n",
        "    acc += 1\n",
        "\n",
        "print(acc/len(SRC))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "783eeb67-00be-42ed-aa9e-5f8c4091071e",
        "id": "UUr5dc7BqYug"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5647208121827412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = list()\n",
        "wrong = list()\n",
        "preds = list()\n",
        "fp = 0\n",
        "\n",
        "for i in range(len(truth)):\n",
        "  pred = preds_L2[i]\n",
        "  if scores_L2[i] < threshold:\n",
        "    pred = torch.tensor(404)\n",
        "  if pred == truth[i]:\n",
        "    correct.append(i)\n",
        "  else:\n",
        "    wrong.append(i)\n",
        "    if truth[i] == torch.tensor(404): # false positive\n",
        "      fp += 1\n",
        "  preds.append(pred)\n",
        "\n",
        "print(\"Correctly classified\", len(correct), \"samples.\",\n",
        "      \"\\nMisclassified\", len(wrong), \"samples.\",\n",
        "      \"\\nFPR:\", fp/(len(truth) - len(src_labels)))  # sanity check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b9eebe8-0109-4e00-d107-dcba42cc5804",
        "id": "wPgvWRwPqYug"
      },
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctly classified 675 samples. \n",
            "Misclassified 2215 samples. \n",
            "FPR: 0.8810656517602283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_FOLDER = 'outputs/classification_results'\n",
        "if not os.path.exists(f'{OUTPUT_FOLDER}/{DATA_NAME}/L2'):\n",
        "  os.makedirs(f'{OUTPUT_FOLDER}/{DATA_NAME}/L2')\n",
        "\n",
        "for sample in tqdm(range(len(truth))):\n",
        "  title = f\"{lab_to_text[truth[sample].item()]}-{lab_to_text[preds[sample].item()]}\"\n",
        "  file = open(f'{OUTPUT_FOLDER}/{DATA_NAME}/L2/{title}.txt', 'a+')\n",
        "  file.write(str(sample)+'\\n')\n",
        "  file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "826f675c-034f-4979-8b51-b80b95c04145",
        "id": "dajak9_gqYug"
      },
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2890/2890 [00:00<00:00, 18458.06it/s]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_SaNR7NyoCf8",
        "cHLt8Bx3oCf9",
        "6m8OvT5ToCf-",
        "WAjZ329foCf_",
        "gjMOZ6MxoCgA",
        "-AUeaNECnbS2",
        "Sni-BAX6U4_Y",
        "-BoYmHdMVDM1",
        "eAoxz5XXomWi",
        "ekoxgrufomWj",
        "9PxBuRRhomWk"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}